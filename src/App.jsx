"use client"

import { useEffect, useRef, useState } from "react"
import "./AppUI.css"
import AvatarLipsync from "./components/Avatar.jsx"

const backendBaseUrl =
  window.location.hostname === "localhost" ? "http://localhost:3000" : "https://nyay-gpt.onrender.com"

// Supported Languages & Greetings
const languages = {
  english: {
    code: "en-IN",
    greeting: "Hello! I'm Nyay GPT ‚Äî your AI legal assistant. Feel free to ask me any legal question.",
  },
  hindi: { code: "hi-IN", greeting: "‡§®‡§Æ‡§∏‡•ç‡§§‡•á! ‡§Æ‡•à‡§Ç ‡§®‡•ç‡§Ø‡§æ‡§Ø GPT ‡§π‡•Ç‡§Å‡•§ ‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§ï‡•ã‡§à ‡§≠‡•Ä ‡§ï‡§æ‡§®‡•Ç‡§®‡•Ä ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§" },
  punjabi: { code: "pa-IN", greeting: "‡®∏‡®§ ‡®∏‡©ç‡®∞‡©Ä ‡®Ö‡®ï‡®æ‡®≤! ‡®Æ‡©à‡®Ç ‡®®‡®ø‡®Ü‡®Ç GPT ‡®π‡®æ‡®Ç‡•§ ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®Æ‡©à‡®®‡©Ç‡©∞ ‡®ï‡©ã‡®à ‡®µ‡©Ä ‡®ï‡®æ‡®®‡©Ç‡©∞‡®®‡©Ä ‡®∏‡®µ‡®æ‡®≤ ‡®™‡©Å‡©±‡®õ ‡®∏‡®ï‡®¶‡©á ‡®π‡©ã‡•§" },
  tamil: { code: "ta-IN", greeting: "‡Æµ‡Æ£‡Æï‡Øç‡Æï‡ÆÆ‡Øç! ‡Æ®‡Ææ‡Æ©‡Øç ‡Æ®‡Æø‡ÆØ‡Ææ‡ÆØ GPT. ‡Æ®‡ØÄ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æé‡Æ©‡Øç‡Æ©‡Æø‡Æü‡ÆÆ‡Øç ‡Æé‡Æ®‡Øç‡Æ§‡Æµ‡Øä‡Æ∞‡ØÅ ‡Æö‡Æü‡Øç‡Æü‡Æï‡Øç ‡Æï‡Øá‡Æ≥‡Øç‡Æµ‡Æø‡ÆØ‡Øà‡ÆØ‡ØÅ‡ÆÆ‡Øç ‡Æï‡Øá‡Æü‡Øç‡Æï‡Æ≤‡Ææ‡ÆÆ‡Øç." },
  marathi: { code: "mr-IN", greeting: "‡§®‡§Æ‡§∏‡•ç‡§ï‡§æ‡§∞! ‡§Æ‡•Ä ‡§®‡•ç‡§Ø‡§æ‡§Ø GPT ‡§Ü‡§π‡•á. ‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§Æ‡§≤‡§æ ‡§ï‡•ã‡§£‡§§‡§æ‡§π‡•Ä ‡§ï‡§æ‡§Ø‡§¶‡•á‡§∂‡•Ä‡§∞ ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§µ‡§ø‡§ö‡§æ‡§∞‡•Ç ‡§∂‡§ï‡§§‡§æ." },
  telugu: { code: "te-IN", greeting: "‡∞®‡∞Æ‡∞∏‡±ç‡∞§‡±á! ‡∞®‡±á‡∞®‡±Å ‡∞®‡±ç‡∞Ø‡∞æ‡∞Ø GPT. ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞®‡∞®‡±ç‡∞®‡±Å ‡∞é‡∞≤‡∞æ‡∞Ç‡∞ü‡∞ø ‡∞ö‡∞ü‡±ç‡∞ü ‡∞∏‡∞Ç‡∞¨‡∞Ç‡∞ß‡∞ø‡∞§ ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞≤‡±Å ‡∞Ö‡∞°‡∞ó‡∞µ‡∞ö‡±ç‡∞ö‡±Å." },
  bengali: { code: "bn-IN", greeting: "‡¶®‡¶Æ‡¶∏‡ßç‡¶ï‡¶æ‡¶∞! ‡¶Ü‡¶Æ‡¶ø ‡¶®‡ßç‡¶Ø‡¶æ‡¶Ø‡¶º GPT‡•§ ‡¶Ü‡¶™‡¶®‡¶ø ‡¶Ü‡¶Æ‡¶æ‡¶ï‡ßá ‡¶Ø‡ßá‡¶ï‡ßã‡¶®‡ßã ‡¶Ü‡¶á‡¶®‡¶ø ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡¶®‡•§" },
  kannada: { code: "kn-IN", greeting: "‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞! ‡≤®‡≤æ‡≤®‡≥Å ‡≤®‡≥ç‡≤Ø‡≤æ‡≤Ø GPT. ‡≤®‡≥Ä‡≤µ‡≥Å ‡≤®‡≤®‡≤ó‡≥Ü ‡≤Ø‡≤æ‡≤µ‡≥Å‡≤¶‡≥á ‡≤ï‡≤æ‡≤®‡≥Ç‡≤®‡≥Å ‡≤™‡≥ç‡≤∞‡≤∂‡≥ç‡≤®‡≥Ü ‡≤ï‡≥á‡≤≥‡≤¨‡≤π‡≥Å‡≤¶‡≥Å." },
  malayalam: { code: "ml-IN", greeting: "‡¥®‡¥Æ‡¥∏‡µç‡¥ï‡¥æ‡¥∞‡¥Ç! ‡¥û‡¥æ‡µª ‡¥®‡µç‡¥Ø‡¥æ‡¥Ø GPT. ‡¥®‡¥ø‡¥ô‡µç‡¥ô‡µæ‡¥ï‡µç‡¥ï‡µç ‡¥é‡¥®‡¥ø‡¥ï‡µç‡¥ï‡µç ‡¥®‡¥ø‡¥Ø‡¥Æ‡¥™‡¥∞‡¥Æ‡¥æ‡¥Ø ‡¥ö‡µã‡¥¶‡µç‡¥Ø‡¥ô‡µç‡¥ô‡µæ ‡¥ö‡µã‡¥¶‡¥ø‡¥ï‡µç‡¥ï‡¥æ‡¥Ç." },
  gujarati: { code: "gu-IN", greeting: "‡™®‡™Æ‡™∏‡´ç‡™§‡´á! ‡™π‡´Å‡™Ç ‡™®‡´ç‡™Ø‡™æ‡™Ø GPT ‡™õ‡´Å‡™Ç. ‡™§‡™Æ‡´á ‡™Æ‡™®‡´á ‡™ï‡´ã‡™à ‡™™‡™£ ‡™ï‡™æ‡™®‡´Ç‡™®‡´Ä ‡™™‡´ç‡™∞‡™∂‡´ç‡™® ‡™™‡´Ç‡™õ‡´ã." },
  urdu: { code: "ur-IN", greeting: "ÿßŸÑÿ≥ŸÑÿßŸÖ ÿπŸÑ€å⁄©ŸÖ! ŸÖ€å⁄∫ ŸÜ€åÿß€ì GPT €ÅŸà⁄∫ÿå ÿ¢Ÿæ ŸÖÿ¨⁄æ ÿ≥€í ⁄©Ÿàÿ¶€å ÿ®⁄æ€å ŸÇÿßŸÜŸàŸÜ€å ÿ≥ŸàÿßŸÑ ŸæŸà⁄Ü⁄æ ÿ≥⁄©ÿ™€í €Å€å⁄∫€î" },
  odia: { code: "or-IN", greeting: "‡¨®‡¨Æ‡¨∏‡≠ç‡¨ï‡¨æ‡¨∞! ‡¨Æ‡≠Å‡¨Å ‡¨®‡≠ç‡≠ü‡¨æ‡≠ü GPT‡•§ ‡¨Ü‡¨™‡¨£ ‡¨Æ‡≠ã‡¨§‡≠á ‡¨ï‡≠å‡¨£‡¨∏‡¨ø ‡¨Ü‡¨á‡¨®‡¨ø‡¨ï ‡¨™‡≠ç‡¨∞‡¨∂‡≠ç‡¨® ‡¨™‡¨ö‡¨æ‡¨∞‡¨ø‡¨™‡¨æ‡¨∞‡¨ø‡¨¨‡≠á‡•§" },
}

const languageKeywords = {
  english: ["english", "‡§á‡§Ç‡§ó‡•ç‡§≤‡§ø‡§∂", "‡§Ö‡§Ç‡§ó‡•ç‡§∞‡•á‡§ú‡•Ä"],
  hindi: ["hindi", "‡§π‡§ø‡§Ç‡§¶‡•Ä"],
  punjabi: ["punjabi", "‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä", "‡§™‡§Ç‡§ú‡§æ‡§¨‡•Ä"],
  tamil: ["tamil", "‡§§‡§Æ‡§ø‡§≤"],
  marathi: ["marathi", "‡§Æ‡§∞‡§æ‡§†‡•Ä"],
  telugu: ["telugu", "‡§§‡•á‡§≤‡•Å‡§ó‡•Ç"],
  bengali: ["bengali", "‡¶¨‡ßá‡¶ô‡ßç‡¶ó‡¶≤‡¶ø", "‡¶¨‡¶æ‡¶ô‡¶æ‡¶≤‡¶ø", "‡§¨‡§Ç‡§ó‡§æ‡§≤‡•Ä"],
  kannada: ["kannada", "‡≤ï‡≤®‡≥ç‡≤®‡≤°", "‡§ï‡§®‡•ç‡§®‡§°‡§º", "‡≤ï‡≤®‡≥ç‡≤®‡≤°"],
  malayalam: ["malayalam", "‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç", "‡§Æ‡§≤‡§Ø‡§æ‡§≤‡§Æ"],
  gujarati: ["gujarati", "‡™ó‡´Å‡™ú‡™∞‡™æ‡™§‡´Ä", "‡§ó‡•Å‡§ú‡§∞‡§æ‡§§‡•Ä"],
  urdu: ["urdu", "ÿßÿ±ÿØŸà", "‡§â‡§∞‡•ç‡§¶‡•Ç"],
  odia: ["odia", "odiya", "‡¨ì‡¨°‡¨º‡¨ø‡¨Ü", "‡§ì‡§°‡§º‡§ø‡§Ø‡§æ"],
}

const initialGreeting =
  "‡§Ü‡§™ ‡§ï‡§æ‡§®‡•Ç‡§®‡•Ä ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§§‡§ï ‡§™‡§π‡•Å‡§Å‡§ö ‡§ö‡•Å‡§ï‡•á ‡§π‡•à‡§Ç‡•§ ‡§Ü‡§™‡§ï‡•Ä ‡§¨‡•á‡§π‡§§‡§∞ ‡§Æ‡§¶‡§¶ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡•É‡§™‡§Ø‡§æ ‡§¨‡§§‡§æ‡§è‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§™‡§∏‡§Ç‡§¶‡•Ä‡§¶‡§æ ‡§≠‡§æ‡§∑‡§æ ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à? For example: Hindi, English, Gujrati.       You have accessed legal aid , for your better help , please tell us your preferred language for example english , hindi , gujrati"

const languageGreetings = {
  hindi:
    "‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§ú‡•Ä, ‡§Æ‡•à‡§Ç ‡§®‡§µ‡•ç‡§Ø‡§æ swaraj ai ‡§∏‡•á ‡§Ü‡§™‡§ï‡•Ä ‡§≤‡•Ä‡§ó‡§≤ ‡§è‡§ú‡•á‡§Ç‡§ü‡•§ ‡§Ü‡§™‡§ï‡•Ä ‡§¨‡•á‡§π‡§§‡§∞ ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§¨‡§§‡§æ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§Ü‡§™‡§ï‡•ã ‡§ï‡§ø‡§∏ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§ï‡•Ä ‡§ï‡§æ‡§®‡•Ç‡§®‡•Ä ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§ö‡§æ‡§π‡§ø‡§è ‡§Ø‡§æ ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§á‡§Æ‡§∞‡§ú‡•á‡§Ç‡§∏‡•Ä ‡§Æ‡•á‡§Ç ‡§π‡•à‡§Ç?",
  english:
    "Hello! I am Navya, your legal agent. For better assistance, can you tell me what help you need or if you are in an emergency?",
  punjabi:
    "‡®∏‡®§ ‡®∏‡©ç‡®∞‡©Ä ‡®Ö‡®ï‡®æ‡®≤ ‡®ú‡©Ä, ‡®Æ‡©à‡®Ç ‡®®‡®µ‡®ø‡®Ü, ‡®§‡©Å‡®π‡®æ‡®°‡©Ä ‡®≤‡©Ä‡®ó‡®≤ ‡®è‡®ú‡©∞‡®ü ‡®π‡®æ‡®Ç‡•§ ‡®§‡©Å‡®π‡®æ‡®°‡©Ä ‡®¨‡®ø‡®π‡®§‡®∞ ‡®Æ‡®¶‡®¶ ‡®≤‡®à, ‡®ï‡©Ä ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®¶‡©±‡®∏ ‡®∏‡®ï‡®¶‡©á ‡®π‡©ã ‡®ï‡®ø ‡®§‡©Å‡®π‡®æ‡®®‡©Ç‡©∞ ‡®ï‡®ø‡®∏ ‡®ï‡®ø‡®∏‡®Æ ‡®¶‡©Ä ‡®ï‡®æ‡®®‡©Ç‡©∞‡®®‡©Ä ‡®Æ‡®¶‡®¶ ‡®ö‡®æ‡®π‡©Ä‡®¶‡©Ä ‡®π‡©à ‡®ú‡®æ‡®Ç ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®ê‡®Æ‡®∞‡®ú‡©à‡®Ç‡®∏‡©Ä ‡®µ‡®ø‡©±‡®ö ‡®π‡©ã?",
  tamil:
    "‡Æµ‡Æ£‡Æï‡Øç‡Æï‡ÆÆ‡Øç, ‡Æ®‡Ææ‡Æ©‡Øç ‡Æ®‡Æµ‡Øç‡ÆØ‡Ææ, ‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æö‡Æü‡Øç‡Æü ‡Æâ‡Æ§‡Æµ‡Æø‡ÆØ‡Ææ‡Æ≥‡Æ∞‡Øç. ‡Æö‡Æø‡Æ±‡Æ®‡Øç‡Æ§ ‡Æâ‡Æ§‡Æµ‡Æø‡Æï‡Øç‡Æï‡Ææ‡Æï, ‡Æ®‡ØÄ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æé‡Æ©‡Øç‡Æ© ‡Æâ‡Æ§‡Æµ‡Æø ‡Æ§‡Øá‡Æµ‡Øà ‡Æé‡Æ©‡Øç‡Æ±‡ØÅ ‡ÆÖ‡Æ≤‡Øç‡Æ≤‡Æ§‡ØÅ ‡ÆÖ‡Æµ‡Æö‡Æ∞ ‡Æ®‡Æø‡Æ≤‡Øà‡ÆÆ‡Øà‡ÆØ‡Æø‡Æ≤‡Øç ‡Æâ‡Æ≥‡Øç‡Æ≥‡ØÄ‡Æ∞‡Øç‡Æï‡Æ≥‡Ææ ‡Æé‡Æ©‡Øç‡Æ±‡ØÅ ‡Æö‡Øä‡Æ≤‡Øç‡Æ≤ ‡ÆÆ‡ØÅ‡Æü‡Æø‡ÆØ‡ØÅ‡ÆÆ‡Ææ?",
  marathi:
    "‡§®‡§Æ‡§∏‡•ç‡§ï‡§æ‡§∞, ‡§Æ‡•Ä ‡§®‡§µ‡•ç‡§Ø‡§æ, ‡§§‡•Å‡§Æ‡§ö‡•Ä ‡§≤‡•Ä‡§ó‡§≤ ‡§è‡§ú‡§Ç‡§ü. ‡§§‡•Å‡§Æ‡§ö‡•ç‡§Ø‡§æ ‡§â‡§§‡•ç‡§§‡§Æ ‡§Æ‡§¶‡§§‡•Ä‡§∏‡§æ‡§†‡•Ä, ‡§ï‡•É‡§™‡§Ø‡§æ ‡§∏‡§æ‡§Ç‡§ó‡§æ ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§≤‡§æ ‡§ï‡•ã‡§£‡§§‡•ç‡§Ø‡§æ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞‡§ö‡•Ä ‡§ï‡§æ‡§Ø‡§¶‡•á‡§∂‡•Ä‡§∞ ‡§Æ‡§¶‡§§ ‡§π‡§µ‡•Ä ‡§Ü‡§π‡•á ‡§ï‡§ø‡§Ç‡§µ‡§æ ‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§Ü‡§£‡•Ä‡§¨‡§æ‡§£‡•Ä ‡§∏‡•ç‡§•‡§ø‡§§‡•Ä‡§§ ‡§Ü‡§π‡§æ‡§§ ‡§ï‡§æ?",
  telugu:
    "‡∞®‡∞Æ‡∞∏‡±ç‡∞§‡±á, ‡∞®‡±á‡∞®‡±Å ‡∞®‡∞µ‡±ç‡∞Ø‡∞æ, ‡∞Æ‡±Ä ‡∞≤‡±Ä‡∞ó‡∞≤‡±ç ‡∞è‡∞ú‡±Ü‡∞Ç‡∞ü‡±ç. ‡∞Æ‡±Ä‡∞ï‡±Å ‡∞Æ‡±Ü‡∞∞‡±Å‡∞ó‡±à‡∞® ‡∞∏‡∞π‡∞æ‡∞Ø‡∞Ç ‡∞Ö‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞ö‡±á‡∞Ç‡∞¶‡±Å‡∞ï‡±Å, ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞è ‡∞µ‡∞ø‡∞ß‡∞Æ‡±à‡∞® ‡∞ö‡∞ü‡±ç‡∞ü ‡∞∏‡∞π‡∞æ‡∞Ø‡∞Ç ‡∞ï‡∞æ‡∞µ‡∞æ‡∞≤‡±ã ‡∞≤‡±á‡∞¶‡∞æ ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞é‡∞Æ‡∞∞‡±ç‡∞ú‡±Ü‡∞®‡±ç‡∞∏‡±Ä‡∞≤‡±ã ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞∞‡∞æ ‡∞Ö‡∞®‡∞ø ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞ó‡∞≤‡∞∞‡∞æ?",
  bengali:
    "‡¶®‡¶Æ‡¶∏‡ßç‡¶ï‡¶æ‡¶∞, ‡¶Ü‡¶Æ‡¶ø ‡¶®‡¶¨‡ßç‡¶Ø‡¶æ, ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶≤‡¶ø‡¶ó‡ßç‡¶Ø‡¶æ‡¶≤ ‡¶è‡¶ú‡ßá‡¶®‡ßç‡¶ü‡•§ ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶Ü‡¶∞‡¶ì ‡¶≠‡¶æ‡¶≤ ‡¶∏‡¶π‡¶æ‡¶Ø‡¶º‡¶§‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø, ‡¶¶‡¶Ø‡¶º‡¶æ ‡¶ï‡¶∞‡ßá ‡¶¨‡¶≤‡ßÅ‡¶® ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡ßÄ ‡¶ß‡¶∞‡¶®‡ßá‡¶∞ ‡¶Ü‡¶á‡¶®‡¶ø ‡¶∏‡¶π‡¶æ‡¶Ø‡¶º‡¶§‡¶æ ‡¶ö‡¶æ‡¶® ‡¶¨‡¶æ ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ú‡¶∞‡ßÅ‡¶∞‡¶ø ‡¶Ö‡¶¨‡¶∏‡ßç‡¶•‡¶æ‡¶Ø‡¶º ‡¶∞‡¶Ø‡¶º‡ßá‡¶õ‡ßá‡¶® ‡¶ï‡¶ø‡¶®‡¶æ‡•§",
  kannada:
    "‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞, ‡≤®‡≤æ‡≤®‡≥Å ‡≤®‡≤µ‡≥ç‡≤Ø‡≤æ, ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤≤‡≥Ä‡≤ó‡≤≤‡≥ç ‡≤è‡≤ú‡≥Ü‡≤Ç‡≤ü‡≥ç. ‡≤â‡≤§‡≥ç‡≤§‡≤Æ ‡≤∏‡≤π‡≤æ‡≤Ø‡≤ï‡≥ç‡≤ï‡≤æ‡≤ó‡≤ø, ‡≤®‡≤ø‡≤Æ‡≤ó‡≥Ü ‡≤Ø‡≤æ‡≤µ ‡≤∞‡≥Ä‡≤§‡≤ø‡≤Ø ‡≤ï‡≤æ‡≤®‡≥Ç‡≤®‡≥Å ‡≤∏‡≤π‡≤æ‡≤Ø ‡≤¨‡≥á‡≤ï‡≥Å ‡≤Ö‡≤•‡≤µ‡≤æ ‡≤®‡≥Ä‡≤µ‡≥Å ‡≤§‡≥Å‡≤∞‡≥ç‡≤§‡≥Å ‡≤™‡≤∞‡≤ø‡≤∏‡≥ç‡≤•‡≤ø‡≤§‡≤ø‡≤Ø‡≤≤‡≥ç‡≤≤‡≤ø ‡≤á‡≤¶‡≥ç‡≤¶‡≥Ä‡≤∞‡≤æ ‡≤é‡≤Ç‡≤¨‡≥Å‡≤¶‡≤®‡≥ç‡≤®‡≥Å ‡≤π‡≥á‡≤≥‡≤ø.",
  malayalam:
    "‡¥®‡¥Æ‡¥∏‡µç‡¥ï‡¥æ‡¥∞‡¥Ç, ‡¥û‡¥æ‡µª ‡¥®‡¥µ‡µç‡¥Ø, ‡¥®‡¥ø‡¥ô‡µç‡¥ô‡¥≥‡µÅ‡¥ü‡µÜ ‡¥≤‡µÄ‡¥ó‡µΩ ‡¥è‡¥ú‡¥®‡µç‡¥±‡µç. ‡¥Æ‡¥ø‡¥ï‡¥ö‡µç‡¥ö ‡¥∏‡¥π‡¥æ‡¥Ø‡¥§‡µç‡¥§‡¥ø‡¥®‡¥æ‡¥Ø‡¥ø, ‡¥®‡¥ø‡¥ô‡µç‡¥ô‡µæ‡¥ï‡µç‡¥ï‡µç ‡¥é‡¥®‡µç‡¥§‡µç ‡¥§‡¥∞‡¥§‡µç‡¥§‡¥ø‡¥≤‡µÅ‡¥≥‡µç‡¥≥ ‡¥®‡¥ø‡¥Ø‡¥Æ ‡¥∏‡¥π‡¥æ‡¥Ø‡¥Ç ‡¥µ‡µá‡¥£‡¥Æ‡µÜ‡¥®‡µç‡¥®‡µç ‡¥Ö‡¥≤‡µç‡¥≤‡µÜ‡¥ô‡µç‡¥ï‡¥ø‡µΩ ‡¥®‡¥ø‡¥ô‡µç‡¥ô‡µæ ‡¥Ö‡¥ü‡¥ø‡¥Ø‡¥®‡µç‡¥§‡¥∞‡¥æ‡¥µ‡¥∏‡µç‡¥•‡¥Ø‡¥ø‡¥≤‡¥æ‡¥£‡µã ‡¥é‡¥®‡µç‡¥®‡µç ‡¥™‡¥±‡¥Ø‡¥æ‡¥Æ‡µã?",
  gujarati:
    "‡™®‡™Æ‡™∏‡´ç‡™§‡´á, ‡™π‡´Å‡™Ç ‡™®‡™µ‡´ç‡™Ø‡™æ, ‡™§‡™Æ‡™æ‡™∞‡´Ä ‡™≤‡´Ä‡™ó‡™≤ ‡™è‡™ú‡™®‡´ç‡™ü ‡™õ‡´Å‡™Ç. ‡™§‡™Æ‡™æ‡™∞‡´Ä ‡™µ‡™ß‡´Å ‡™∏‡™æ‡™∞‡´Ä ‡™Æ‡™¶‡™¶ ‡™Æ‡™æ‡™ü‡´á, ‡™ï‡´É‡™™‡™æ ‡™ï‡™∞‡´Ä‡™®‡´á ‡™ï‡™π‡´ã ‡™§‡™Æ‡™®‡´á ‡™ï‡™à ‡™™‡´ç‡™∞‡™ï‡™æ‡™∞‡™®‡´Ä ‡™ï‡™æ‡™®‡´Ç‡™®‡´Ä ‡™Æ‡™¶‡™¶ ‡™ú‡´ã‡™à‡™è ‡™õ‡´á ‡™Ö‡™•‡™µ‡™æ ‡™§‡™Æ‡´á ‡™á‡™Æ‡™∞‡™ú‡™®‡´ç‡™∏‡´Ä ‡™Æ‡™æ‡™Ç ‡™õ‡´ã?",
  urdu: "ÿßŸÑÿ≥ŸÑÿßŸÖ ÿπŸÑ€å⁄©ŸÖÿå ŸÖ€å⁄∫ ŸÜŸà€åÿßÿå ÿ¢Ÿæ ⁄©€å ŸÇÿßŸÜŸàŸÜ€å ÿß€åÿ¨ŸÜŸπ €ÅŸà⁄∫€î ÿ¢Ÿæ ⁄©€å ÿ®€Åÿ™ÿ± ŸÖÿØÿØ ⁄©€í ŸÑ€å€íÿå ⁄©€åÿß ÿ¢Ÿæ ÿ®ÿ™ÿß ÿ≥⁄©ÿ™€í €Å€å⁄∫ ÿ¢Ÿæ ⁄©Ÿà ⁄©ÿ≥ ⁄Ü€åÿ≤ ‡§ï‡•Ä ŸÇÿßŸÜŸàŸÜ€å ŸÖÿØÿØ ‡§ö‡§æ‡§π‡§ø‡§è ‡§Ø‡§æ ÿ¢Ÿæ ÿß€åŸÖÿ±ÿ¨€åŸÜÿ≥€å ŸÖ€å⁄∫ €Å€å⁄∫ÿü",
  odia: "‡¨®‡¨Æ‡¨∏‡≠ç‡¨ï‡¨æ‡¨∞, ‡¨Æ‡≠Å‡¨Å ‡¨®‡¨¨‡≠ç‡≠ü‡¨æ, ‡¨Ü‡¨™‡¨£‡¨ô‡≠ç‡¨ï‡¨∞ ‡¨≤‡¨ø‡¨ó‡¨æ‡¨≤‡≠ç ‡¨è‡¨ú‡≠á‡¨£‡≠ç‡¨ü‡•§ ‡¨Ü‡¨™‡¨£‡¨ô‡≠ç‡¨ï‡≠Å ‡¨≠‡¨≤ ‡¨∏‡¨π‡¨Ø‡≠ã‡¨ó ‡¨¶‡≠á‡¨¨‡¨æ ‡¨™‡¨æ‡¨á‡¨Å, ‡¨¶‡≠ü‡¨æ‡¨ï‡¨∞‡¨ø ‡¨ï‡¨π‡¨®‡≠ç‡¨§‡≠Å ‡¨Ü‡¨™‡¨£ ‡¨ï‡≠á‡¨â‡¨Å ‡¨™‡≠ç‡¨∞‡¨ï‡¨æ‡¨∞‡¨∞ ‡¨Ü‡¨á‡¨®‡¨ø‡¨ï ‡¨∏‡¨π‡¨Ø‡≠ã‡¨ó ‡¨ö‡¨æ‡¨π‡¨æ‡¨Å‡¨®‡≠ç‡¨§‡¨ø ‡¨ï‡¨ø‡¨Æ‡≠ç‡¨¨‡¨æ ‡¨Ü‡¨™‡¨£ ‡¨Ü‡¨™‡¨æ‡¨§‡≠ç‡¨ï‡¨æ‡¨≥‡≠Ä‡¨® ‡¨∏‡≠ç‡¨•‡¨ø‡¨§‡¨ø‡¨∞‡≠á ‡¨Ö‡¨õ‡¨®‡≠ç‡¨§‡¨ø ‡¨ï‡¨ø?",
}

export default function App() {
  const recognitionRef = useRef(null)
  const audioRef = useRef(null)
  const apiCallInProgressRef = useRef(false)
  const audioContextRef = useRef(null)
  const analyserRef = useRef(null)
  const animationFrameRef = useRef(null)

  const [connected, setConnected] = useState(false)
  const [muted, setMuted] = useState(false)
  const [speaking, setSpeaking] = useState(false)
  const [userSpeaking, setUserSpeaking] = useState(false)
  const [timer, setTimer] = useState(0)
  const [currentLang, setCurrentLang] = useState("")
  const [langSelected, setLangSelected] = useState(false)
  const [recognitionKey, setRecognitionKey] = useState(0)
  const [history, setHistory] = useState([])
  const [policeStations, setPoliceStations] = useState([])
  const [userPos, setUserPos] = useState(null)
  const [showStations, setShowStations] = useState(false)
  const [selectedStation, setSelectedStation] = useState(null)
  const [phase, setPhase] = useState("init")
  const [mouthOpen, setMouthOpen] = useState(0)
  const [audioData, setAudioData] = useState(null)
  const [callRequestLoading, setCallRequestLoading] = useState(false)

  const timerRef = useRef(null)
  const utteranceIdRef = useRef(0)

  const MAPS_EMBED_API_KEY = import.meta.env.VITE_GOOGLE_MAPS_API_KEY

  // Audio unlock for mobile devices
  useEffect(() => {
    const unlockAudio = () => {
      try {
        if (!audioContextRef.current) {
          audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)()
        }
        if (audioContextRef.current.state === "suspended") {
          audioContextRef.current.resume()
        }
        const buffer = audioContextRef.current.createBuffer(1, 1, 22050)
        const source = audioContextRef.current.createBufferSource()
        source.buffer = buffer
        source.connect(audioContextRef.current.destination)
        source.start(0)
      } catch (e) {
        console.log("Audio unlock failed:", e)
      }
      document.removeEventListener("touchend", unlockAudio, true)
      document.removeEventListener("click", unlockAudio, true)
    }
    document.addEventListener("touchend", unlockAudio, true)
    document.addEventListener("click", unlockAudio, true)
    return () => {
      document.removeEventListener("touchend", unlockAudio, true)
      document.removeEventListener("click", unlockAudio, true)
    }
  }, [])

  // Speech recognition setup
  useEffect(() => {
    if (!connected) return
    if (muted || speaking) return

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
    if (!SpeechRecognition) {
      alert("Speech recognition not supported in this browser. Use the latest Chrome.")
      return
    }
    const langToUse = currentLang && languages[currentLang] ? languages[currentLang].code : "hi-IN"
    const recognition = new SpeechRecognition()
    recognition.lang = langToUse
    recognition.continuous = true
    recognition.interimResults = false

    let stoppedByApp = false

    recognition.onresult = async (event) => {
      if (muted || speaking || apiCallInProgressRef.current) return

      setUserSpeaking(true)
      setTimeout(() => setUserSpeaking(false), 1200)
      recognition.stop()

      utteranceIdRef.current += 1
      const thisUtterance = utteranceIdRef.current
      const userSpeech = event.results[event.results.length - 1][0].transcript.toLowerCase().trim()

      if (phase === "askLang") {
        let detectedLang = null
        Object.keys(languageKeywords).forEach((lang) => {
          languageKeywords[lang].forEach((keyword) => {
            if (userSpeech.includes(keyword)) {
              detectedLang = lang
            }
          })
        })
        if (detectedLang) {
          setCurrentLang(detectedLang)
          setLangSelected(true)
          setRecognitionKey((k) => k + 1)
          setHistory([])
          setPhase("normal")
          await speakText(languageGreetings[detectedLang], detectedLang)
          return
        } else {
          await speakText("‡§ï‡•É‡§™‡§Ø‡§æ ‡§Ö‡§™‡§®‡•Ä ‡§™‡§∏‡§Ç‡§¶‡•Ä‡§¶‡§æ ‡§≠‡§æ‡§∑‡§æ ‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§¶‡•ã‡§¨‡§æ‡§∞‡§æ ‡§¨‡§§‡§æ‡§è‡§Ç‡•§ For example: Hindi, English, Tamil, etc.", "hindi")
          setRecognitionKey((k) => k + 1)
          return
        }
      }

      if (phase === "normal" && !apiCallInProgressRef.current) {
        apiCallInProgressRef.current = true
        setSpeaking(true)
        const newHistory = [...history, { role: "user", content: userSpeech }]
        setHistory(newHistory)
        try {
          const res = await fetch(`${backendBaseUrl}/ask-context`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
              history: newHistory,
              language: currentLang,
            }),
          })
          if (!res.ok) throw new Error(`Server responded with ${res.status}`)
          const data = await res.json()
          if (utteranceIdRef.current === thisUtterance && apiCallInProgressRef.current) {
            setHistory((h) => [...h, { role: "assistant", content: data.reply }])
            await speakText(data.reply, currentLang)
            setRecognitionKey((k) => k + 1)
          }
        } catch (err) {
          console.error("API Error:", err)
          setSpeaking(false)
          setRecognitionKey((k) => k + 1)
        } finally {
          apiCallInProgressRef.current = false
        }
      }
    }

    recognition.onend = () => {
      if (connected && !muted && !stoppedByApp && !speaking) {
        try {
          recognition.start()
        } catch (e) {
          console.log("Recognition restart failed:", e)
        }
      }
    }

    recognitionRef.current = recognition
    try {
      recognition.start()
    } catch (e) {
      console.log("Recognition start failed:", e)
    }

    return () => {
      stoppedByApp = true
      recognition.stop()
    }
  }, [connected, muted, recognitionKey, speaking, phase, currentLang, history])

  // Timer setup
  useEffect(() => {
    if (connected) {
      timerRef.current = setInterval(() => setTimer((t) => t + 1), 1000)
    } else {
      setTimer(0)
      clearInterval(timerRef.current)
    }
    return () => clearInterval(timerRef.current)
  }, [connected])

  // Audio analysis for lip sync
  useEffect(() => {
    const setupHumanizedAudioAnalysis = async () => {
      if (speaking && audioRef.current) {
        try {
          if (!audioContextRef.current) {
            audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)()
          }

          if (audioContextRef.current.state === "suspended") {
            await audioContextRef.current.resume()
          }

          if (!analyserRef.current) {
            analyserRef.current = audioContextRef.current.createAnalyser()
            analyserRef.current.fftSize = 512
            analyserRef.current.smoothingTimeConstant = 0.2

            const source = audioContextRef.current.createMediaElementSource(audioRef.current)
            source.connect(analyserRef.current)
            analyserRef.current.connect(audioContextRef.current.destination)
          }

          const bufferLength = analyserRef.current.frequencyBinCount
          const dataArray = new Uint8Array(bufferLength)

          const analyzeHumanizedAudio = () => {
            if (speaking && analyserRef.current) {
              analyserRef.current.getByteFrequencyData(dataArray)

              const volume = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength / 255
              const veryLowFreq = dataArray.slice(0, 16).reduce((sum, val) => sum + val, 0) / 16 / 255
              const lowFreq = dataArray.slice(16, 32).reduce((sum, val) => sum + val, 0) / 16 / 255
              const midFreq = dataArray.slice(32, 64).reduce((sum, val) => sum + val, 0) / 32 / 255
              const highFreq = dataArray.slice(64, 96).reduce((sum, val) => sum + val, 0) / 32 / 255
              const veryHighFreq = dataArray.slice(96, 128).reduce((sum, val) => sum + val, 0) / 32 / 255

              const humanizedAudioData = {
                volume: volume,
                frequencies: Array.from(dataArray),
                veryLowFreq: veryLowFreq,
                lowFreq: lowFreq,
                midFreq: midFreq,
                highFreq: highFreq,
                veryHighFreq: veryHighFreq,
                timestamp: Date.now(),
              }

              setAudioData(humanizedAudioData)
              animationFrameRef.current = requestAnimationFrame(analyzeHumanizedAudio)
            }
          }

          analyzeHumanizedAudio()
        } catch (error) {
          console.log("Audio analysis failed, using fallback:", error)
          const createRealisticFakeData = () => {
            const baseVolume = 0.4 + Math.random() * 0.4
            const time = Date.now() * 0.001

            return {
              volume: baseVolume * (0.8 + Math.sin(time * 8) * 0.2),
              frequencies: Array.from({ length: 256 }, (_, i) => Math.random() * 100 + 50),
              veryLowFreq: 0.3 + Math.sin(time * 3) * 0.2,
              lowFreq: 0.25 + Math.cos(time * 4) * 0.15,
              midFreq: 0.2 + Math.sin(time * 6) * 0.1,
              highFreq: 0.15 + Math.cos(time * 8) * 0.08,
              veryHighFreq: 0.1 + Math.sin(time * 12) * 0.05,
              timestamp: Date.now(),
            }
          }

          setAudioData(createRealisticFakeData())

          const fakeInterval = setInterval(() => {
            if (speaking) {
              setAudioData(createRealisticFakeData())
            } else {
              clearInterval(fakeInterval)
            }
          }, 50)
        }
      } else {
        if (animationFrameRef.current) {
          cancelAnimationFrame(animationFrameRef.current)
        }
        setAudioData(null)
      }
    }

    setupHumanizedAudioAnalysis()

    return () => {
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current)
      }
    }
  }, [speaking])

  const handleMute = () => {
    setMuted((m) => !m)
    if (!muted) {
      recognitionRef.current?.stop()
      if (audioRef.current) {
        audioRef.current.pause()
        audioRef.current.src = ""
      }
      setSpeaking(false)
    } else {
      setRecognitionKey((k) => k + 1)
    }
  }

  const handleEnd = () => {
    setConnected(false)
    setMuted(false)
    setLangSelected(false)
    setCurrentLang("")
    setHistory([])
    setPoliceStations([])
    setUserPos(null)
    setShowStations(false)
    setSelectedStation(null)
    setPhase("init")
    setCallRequestLoading(false)
    recognitionRef.current?.stop()
    if (audioRef.current) {
      audioRef.current.pause()
      audioRef.current.src = ""
    }
    setSpeaking(false)
    apiCallInProgressRef.current = false

    if (audioContextRef.current) {
      audioContextRef.current.close()
      audioContextRef.current = null
      analyserRef.current = null
    }
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current)
    }
  }

  const speakText = async (text, langKey = currentLang || "hindi") => {
    console.log("üé§ Starting speech:", text.substring(0, 50) + "...")

    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop()
      } catch (e) {}
    }
    if (audioRef.current) {
      audioRef.current.pause()
      audioRef.current.src = ""
    }

    if (audioContextRef.current && analyserRef.current) {
      try {
        audioContextRef.current.close()
      } catch (e) {}
      audioContextRef.current = null
      analyserRef.current = null
    }

    try {
      const res = await fetch(`${backendBaseUrl}/speak`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ text, language: langKey }),
      })

      if (!res.ok) {
        throw new Error(`TTS request failed: ${res.status}`)
      }

      const blob = await res.blob()
      const audioUrl = URL.createObjectURL(blob)
      const audio = new window.Audio(audioUrl)
      audioRef.current = audio

      audio.onended = () => {
        setSpeaking(false)
        setMouthOpen(0)
        setAudioData(null)
      }
      audio.onerror = (e) => {
        console.error("Audio playback error:", e)
        setSpeaking(false)
        setMouthOpen(0)
        setAudioData(null)
      }

      setSpeaking(true)
      try {
        await audio.play()
      } catch (err) {
        console.error("Audio play failed:", err)
        alert("Please tap anywhere on the screen to enable audio, then try again.")
        setSpeaking(false)
        setMouthOpen(0)
        setAudioData(null)
      }
    } catch (error) {
      console.error("TTS error:", error)
      setSpeaking(false)
      setMouthOpen(0)
      setAudioData(null)
    }
  }

  const handleConnect = async () => {
    setConnected(true)
    setMuted(false)
    setLangSelected(false)
    setCurrentLang("")
    setRecognitionKey((k) => k + 1)
    setHistory([])
    setPoliceStations([])
    setUserPos(null)
    setSelectedStation(null)
    setPhase("askLang")
    await speakText(initialGreeting, "hindi")
    setRecognitionKey((k) => k + 1)
  }

  const handleNearbyPolice = () => {
    if (!navigator.geolocation) {
      alert("Geolocation is not supported by your browser")
      return
    }
    navigator.geolocation.getCurrentPosition(
      async (pos) => {
        const { latitude, longitude } = pos.coords
        setUserPos({ lat: latitude, lng: longitude })
        try {
          const res = await fetch(`${backendBaseUrl}/nearby-police?lat=${latitude}&lng=${longitude}`)
          if (!res.ok) {
            throw new Error(`Failed to fetch police stations: ${res.status}`)
          }
          const data = await res.json()
          setPoliceStations(data.stations || [])
          setShowStations(true)
          setSelectedStation(null)
        } catch (e) {
          console.error("Police stations fetch error:", e)
          alert("Failed to fetch police stations. Please try again.")
        }
      },
      (err) => {
        console.error("Geolocation error:", err)
        alert("Location permission denied or unavailable")
      },
    )
  }

  const handleRequestCall = async () => {
    if (callRequestLoading) return

    setCallRequestLoading(true)

    try {
      let phone = localStorage.getItem("nyaygpt_user_phone")
      if (!phone) {
        phone = prompt("üì≤ Enter your phone number (with country code, e.g., +91XXXXXXXXXX):")
        if (!phone) {
          setCallRequestLoading(false)
          return
        }

        // Basic phone validation
        const phoneRegex = /^\+?[1-9]\d{1,14}$/
        if (!phoneRegex.test(phone.replace(/\s+/g, ""))) {
          alert("Please enter a valid phone number with country code")
          setCallRequestLoading(false)
          return
        }

        localStorage.setItem("nyaygpt_user_phone", phone)
      }

      const requestBody = {
        phone: phone.replace(/\s+/g, ""), // Remove spaces
        topic: "Legal Help",
        language: currentLang || "hindi",
      }

      console.log("Sending call request:", requestBody)

      const res = await fetch(`${backendBaseUrl}/request-call`, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          Accept: "application/json",
        },
        body: JSON.stringify(requestBody),
      })

      const responseText = await res.text()
      console.log("Call request response:", res.status, responseText)

      if (res.ok) {
        alert("‚úÖ Call request sent successfully. You should receive a call shortly.")
      } else {
        console.error("Call request failed:", res.status, responseText)
        alert(`‚ùå Call request failed: ${responseText || "Unknown error"}. Please try again.`)
      }
    } catch (error) {
      console.error("Call request error:", error)
      alert("‚ùå Network error. Please check your connection and try again.")
    } finally {
      setCallRequestLoading(false)
    }
  }

  const formatTime = (sec) => `${String(Math.floor(sec / 60)).padStart(2, "0")}:${String(sec % 60).padStart(2, "0")}`

  return (
    <div className="ai-agent-ui-container premium-bg">
      <div className="ai-status-bar">
        <span>{formatTime(timer)} ‚Ä¢ Voice</span>
        <div className="ai-status-icons">
          <span className="ai-status-icon" />
          <span className="ai-status-icon" />
          <span className="ai-status-battery" />
        </div>
      </div>

      <div className="ai-agent-title-premium" style={{ marginTop: 65, textAlign: "center" }}>
        NyayGPT
      </div>
      <div className="ai-agent-subtitle-premium" style={{ textAlign: "center" }}>
        {connected ? "Connected" : "Tap to connect"}
      </div>

      {/* Avatar Face */}
      <div className="avatar-face-container" style={{ width: 220, height: 320, margin: "10px auto" }}>
        <AvatarLipsync
          mouthOpen={mouthOpen}
          speaking={speaking}
          cameraPosition={[0, 1.6, 1.55]}
          cameraTarget={[0, 1.8, 0]}
          audioData={audioData}
        />
      </div>

      {/* Debug Audio Info (Development Only) */}
      {process.env.NODE_ENV === "development" && audioData && (
        <div
          style={{
            position: "fixed",
            top: 10,
            right: 10,
            background: "rgba(0,0,0,0.95)",
            color: "white",
            padding: 12,
            fontSize: 10,
            borderRadius: 8,
            fontFamily: "monospace",
            lineHeight: 1.4,
          }}
        >
          <div style={{ color: "#00ff00", fontWeight: "bold" }}>üó£Ô∏è AUDIO DEBUG</div>
          <div>üé§ Speaking: {speaking ? "YES" : "NO"}</div>
          <div>üîä Volume: {(audioData.volume * 100).toFixed(0)}%</div>
          <div>üîâ VeryLow: {(audioData.veryLowFreq * 100).toFixed(0)}%</div>
          <div>üîâ Low: {(audioData.lowFreq * 100).toFixed(0)}%</div>
          <div>üîâ Mid: {(audioData.midFreq * 100).toFixed(0)}%</div>
          <div>üîâ High: {(audioData.highFreq * 100).toFixed(0)}%</div>
          <div>üîâ VHigh: {(audioData.veryHighFreq * 100).toFixed(0)}%</div>
        </div>
      )}

      {/* Audio Waves */}
      {connected && (
        <div className={`ai-agent-waves${(speaking || userSpeaking) && !muted ? " speaking" : ""}`}>
          {[...Array(10)].map((_, i) => (
            <div className="ai-wave-bar" key={i} />
          ))}
        </div>
      )}

      {/* Control Buttons */}
      {!connected ? (
        <div className="ai-start-btn-row">
          <button className="ai-premium-call-btn" onClick={handleConnect}>
            <span className="ai-call-icon" />
          </button>
          <button className="ai-nearby-btn" onClick={handleNearbyPolice}>
            <span className="ai-location-icon" />
            <div>Nearby Police</div>
          </button>
        </div>
      ) : (
        <div className="ai-agent-btn-row-premium">
          <button className={`ai-mute-btn${muted ? " muted" : ""}`} onClick={handleMute}>
            <span className={`ai-mic-icon${muted ? " off" : ""}`} />
            <div>Mute</div>
          </button>
          <button className="ai-nearby-btn" onClick={handleNearbyPolice}>
            <span className="ai-location-icon" />
            <div>Nearby Police</div>
          </button>
          <button className="ai-end-btn" onClick={handleEnd}>
            <span className="ai-end-icon" />
            <div>End</div>
          </button>
          <button
            className="ai-nearby-btn"
            onClick={handleRequestCall}
            disabled={callRequestLoading}
            style={{
              background: callRequestLoading
                ? "linear-gradient(135deg, #ccc, #999)"
                : "linear-gradient(135deg, #ff9f1a, #ff6e1a)",
              cursor: callRequestLoading ? "not-allowed" : "pointer",
            }}
          >
            <span className="ai-location-icon" />
            <div>{callRequestLoading ? "Requesting..." : "Request Call"}</div>
          </button>
        </div>
      )}

      {/* Police Stations Modal */}
      {showStations && (
        <div
          className="stations-modal-bg"
          onClick={() => {
            setShowStations(false)
            setSelectedStation(null)
          }}
        >
          <div className="stations-modal" onClick={(e) => e.stopPropagation()}>
            <button
              className="close-btn"
              onClick={() => {
                setShowStations(false)
                setSelectedStation(null)
              }}
              aria-label="Close"
            >
              &times;
            </button>
            <h3>Nearby Police Stations</h3>
            {policeStations.length ? (
              <ul>
                {policeStations.map((s, i) => (
                  <li
                    key={i}
                    style={{ cursor: "pointer" }}
                    onClick={() => setSelectedStation(s)}
                    title="Show directions on map"
                  >
                    <b>{s.name}</b>
                    <span>{s.vicinity}</span>
                  </li>
                ))}
              </ul>
            ) : (
              <div>No nearby police stations found.</div>
            )}
          </div>
        </div>
      )}

      {/* Directions Modal */}
      {selectedStation && userPos && (
        <div className="directions-modal-bg" onClick={() => setSelectedStation(null)}>
          <div className="directions-modal" onClick={(e) => e.stopPropagation()}>
            <button className="close-btn" onClick={() => setSelectedStation(null)} aria-label="Close">
              &times;
            </button>
            <h3>
              Directions to <span style={{ color: "#29489c" }}>{selectedStation.name}</span>
            </h3>
            <iframe
              width="100%"
              height="380"
              frameBorder="0"
              style={{ border: 0, borderRadius: "12px" }}
              allowFullScreen
              loading="lazy"
              src={
                MAPS_EMBED_API_KEY
                  ? `https://www.google.com/maps/embed/v1/directions?key=${MAPS_EMBED_API_KEY}` +
                    `&origin=${userPos.lat},${userPos.lng}` +
                    `&destination=${selectedStation.lat},${selectedStation.lng}` +
                    `&mode=driving`
                  : undefined
              }
              title="Directions Map"
            />
            {!MAPS_EMBED_API_KEY && (
              <div style={{ color: "red", marginTop: 16 }}>
                API Key missing. Please set VITE_GOOGLE_MAPS_API_KEY in your .env file.
              </div>
            )}
          </div>
        </div>
      )}
    </div>
  )
}
