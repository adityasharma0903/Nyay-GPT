import { useEffect, useRef, useState } from "react";
import "./AppUI.css";

// 1. Supported Languages & Greetings
const languages = {
  english:   { code: "en-IN", greeting: "Hello! Iâ€™m Nyay GPT â€” your AI legal assistant. Feel free to ask me any legal question." },
  hindi:     { code: "hi-IN", greeting: "à¤¨à¤®à¤¸à¥à¤¤à¥‡! à¤®à¥ˆà¤‚ à¤¨à¥à¤¯à¤¾à¤¯ GPT à¤¹à¥‚à¤à¥¤ à¤†à¤ª à¤®à¥à¤à¤¸à¥‡ à¤•à¥‹à¤ˆ à¤­à¥€ à¤•à¤¾à¤¨à¥‚à¤¨à¥€ à¤¸à¤µà¤¾à¤² à¤ªà¥‚à¤› à¤¸à¤•à¤¤à¥‡ à¤¹à¥ˆà¤‚à¥¤" },
  punjabi:   { code: "pa-IN", greeting: "à¨¸à¨¤ à¨¸à©à¨°à©€ à¨…à¨•à¨¾à¨²! à¨®à©ˆà¨‚ à¨¨à¨¿à¨†à¨‚ GPT à¨¹à¨¾à¨‚à¥¤ à¨¤à©à¨¸à©€à¨‚ à¨®à©ˆà¨¨à©‚à©° à¨•à©‹à¨ˆ à¨µà©€ à¨•à¨¾à¨¨à©‚à©°à¨¨à©€ à¨¸à¨µà¨¾à¨² à¨ªà©à©±à¨› à¨¸à¨•à¨¦à©‡ à¨¹à©‹à¥¤" },
  tamil:     { code: "ta-IN", greeting: "à®µà®£à®•à¯à®•à®®à¯! à®¨à®¾à®©à¯ à®¨à®¿à®¯à®¾à®¯ GPT. à®¨à¯€à®™à¯à®•à®³à¯ à®Žà®©à¯à®©à®¿à®Ÿà®®à¯ à®Žà®¨à¯à®¤à®µà¯Šà®°à¯ à®šà®Ÿà¯à®Ÿà®•à¯ à®•à¯‡à®³à¯à®µà®¿à®¯à¯à®®à¯ à®•à¯‡à®Ÿà¯à®•à®²à®¾à®®à¯." },
  marathi:   { code: "mr-IN", greeting: "à¤¨à¤®à¤¸à¥à¤•à¤¾à¤°! à¤®à¥€ à¤¨à¥à¤¯à¤¾à¤¯ GPT à¤†à¤¹à¥‡. à¤¤à¥à¤®à¥à¤¹à¥€ à¤®à¤²à¤¾ à¤•à¥‹à¤£à¤¤à¤¾à¤¹à¥€ à¤•à¤¾à¤¯à¤¦à¥‡à¤¶à¥€à¤° à¤ªà¥à¤°à¤¶à¥à¤¨ à¤µà¤¿à¤šà¤¾à¤°à¥‚ à¤¶à¤•à¤¤à¤¾." },
  telugu:    { code: "te-IN", greeting: "à°¨à°®à°¸à±à°¤à±‡! à°¨à±‡à°¨à± à°¨à±à°¯à°¾à°¯ GPT. à°®à±€à°°à± à°¨à°¨à±à°¨à± à°Žà°²à°¾à°‚à°Ÿà°¿ à°šà°Ÿà±à°Ÿ à°¸à°‚à°¬à°‚à°§à°¿à°¤ à°ªà±à°°à°¶à±à°¨à°²à±ˆà°¨à°¾ à°…à°¡à°—à°µà°šà±à°šà±." },
  bengali:   { code: "bn-IN", greeting: "à¦¨à¦®à¦¸à§à¦•à¦¾à¦°! à¦†à¦®à¦¿ à¦¨à§à¦¯à¦¾à¦¯à¦¼ GPTà¥¤ à¦†à¦ªà¦¨à¦¿ à¦†à¦®à¦¾à¦•à§‡ à¦¯à§‡à¦•à§‹à¦¨à§‹ à¦†à¦‡à¦¨à¦¿ à¦ªà§à¦°à¦¶à§à¦¨ à¦•à¦°à¦¤à§‡ à¦ªà¦¾à¦°à§‡à¦¨à¥¤" },
  kannada:   { code: "kn-IN", greeting: "à²¨à²®à²¸à³à²•à²¾à²°! à²¨à²¾à²¨à³ à²¨à³à²¯à²¾à²¯ GPT. à²¨à³€à²µà³ à²¨à²¨à²—à³† à²¯à²¾à²µà³à²¦à³‡ à²•à²¾à²¨à³‚à²¨à³ à²ªà³à²°à²¶à³à²¨à³† à²•à³‡à²³à²¬à²¹à³à²¦à³." },
  malayalam: { code: "ml-IN", greeting: "à´¨à´®à´¸àµà´•à´¾à´°à´‚! à´žà´¾àµ» à´¨àµà´¯à´¾à´¯ GPT. à´¨à´¿à´™àµà´™àµ¾à´•àµà´•àµ à´Žà´¨à´¿à´•àµà´•àµ à´¨à´¿à´¯à´®à´ªà´°à´®à´¾à´¯ à´šàµ‹à´¦àµà´¯à´™àµà´™àµ¾ à´šàµ‹à´¦à´¿à´•àµà´•à´¾à´‚." },
  gujarati:  { code: "gu-IN", greeting: "àª¨àª®àª¸à«àª¤à«‡! àª¹à«àª‚ àª¨à«àª¯àª¾àª¯ GPT àª›à«àª‚. àª¤àª®à«‡ àª®àª¨à«‡ àª•à«‹àªˆ àªªàª£ àª•àª¾àª¨à«‚àª¨à«€ àªªà«àª°àª¶à«àª¨ àªªà«‚àª›à«‹." },
  urdu:      { code: "ur-IN", greeting: "Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÛŒÚ©Ù…! Ù…ÛŒÚº Ù†ÛŒØ§Û“ GPT ÛÙˆÚºØŒ Ø¢Ù¾ Ù…Ø¬Ú¾ Ø³Û’ Ú©ÙˆØ¦ÛŒ Ø¨Ú¾ÛŒ Ù‚Ø§Ù†ÙˆÙ†ÛŒ Ø³ÙˆØ§Ù„ Ù¾ÙˆÚ†Ú¾ Ø³Ú©ØªÛ’ ÛÛŒÚºÛ”" },
  odia:      { code: "or-IN", greeting: "à¬¨à¬®à¬¸à­à¬•à¬¾à¬°! à¬®à­à¬ à¬¨à­à­Ÿà¬¾à­Ÿ GPTà¥¤ à¬†à¬ªà¬£ à¬®à­‹à¬¤à­‡ à¬•à­Œà¬£à¬¸à¬¿ à¬†à¬‡à¬¨à¬¿à¬• à¬ªà­à¬°à¬¶à­à¬¨ à¬ªà¬šà¬¾à¬°à¬¿à¬ªà¬¾à¬°à¬¿à¬¬à­‡à¥¤" },
};

// 2. Keywords for Speech Detection in Multiple Scripts (Add as many variants as you like)
const languageKeywords = {
  english:   ["english", "à¤‡à¤‚à¤—à¥à¤²à¤¿à¤¶", "à¤…à¤‚à¤—à¥à¤°à¥‡à¤œà¥€"],
  hindi:     ["hindi", "à¤¹à¤¿à¤‚à¤¦à¥€"],
  punjabi:   ["punjabi", "à¨ªà©°à¨œà¨¾à¨¬à©€", "à¤ªà¤‚à¤œà¤¾à¤¬à¥€"],
  tamil:     ["tamil", "à¤¤à¤®à¤¿à¤²"],
  marathi:   ["marathi", "à¤®à¤°à¤¾à¤ à¥€"],
  telugu:    ["telugu", "à¤¤à¥‡à¤²à¥à¤—à¥‚"],
  bengali:   ["bengali", "à¦¬à§‡à¦™à§à¦—à¦²à¦¿", "à¤¬à¤‚à¤—à¤¾à¤²à¥€"],
  kannada:   ["kannada", "à²•à²¨à³à²¨à²¡", "à¤•à¤¨à¥à¤¨à¤¡à¤¼", "à¤•à¤¨à¥à¤¨à¤¡"],
  malayalam: ["malayalam", "à´®à´²à´¯à´¾à´³à´‚", "à¤®à¤²à¤¯à¤¾à¤²à¤®"],
  gujarati:  ["gujarati", "àª—à«àªœàª°àª¾àª¤à«€", "à¤—à¥à¤œà¤°à¤¾à¤¤à¥€"],
  urdu:      ["urdu", "Ø§Ø±Ø¯Ùˆ", "à¤‰à¤°à¥à¤¦à¥‚"],
  odia:      ["odia", "odiya", "à¬“à¬¡à¬¼à¬¿à¬†", "à¤“à¤¡à¤¼à¤¿à¤¯à¤¾"],
};

export default function App() {
  const recognitionRef = useRef(null);
  const audioRef = useRef(null);

  const [connected, setConnected] = useState(false);
  const [muted, setMuted] = useState(false);
  const [speaking, setSpeaking] = useState(false); // AI speaking
  const [userSpeaking, setUserSpeaking] = useState(false); // User speaking (for waveform)
  const [timer, setTimer] = useState(0);
  const [currentLang, setCurrentLang] = useState("hindi"); // Default: Hindi
  const [langSelected, setLangSelected] = useState(false); // LOCKED after first selection
  const [recognitionKey, setRecognitionKey] = useState(0); // for force re-creation
  const [history, setHistory] = useState([]); // To store conversation history

  const timerRef = useRef(null);
  const utteranceIdRef = useRef(0); // For reliable barge-in

  // Timer logic
  useEffect(() => {
    if (connected) {
      timerRef.current = setInterval(() => setTimer((t) => t + 1), 1000);
    } else {
      setTimer(0);
      clearInterval(timerRef.current);
    }
    return () => clearInterval(timerRef.current);
  }, [connected]);

  // Speech recognition & logic
  useEffect(() => {
    if (!connected) return;

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    const recognition = new SpeechRecognition();
    recognition.lang = languages[currentLang].code;
    recognition.continuous = true;
    recognition.interimResults = false;

    let stoppedByApp = false;

    recognition.onresult = async (event) => {
      if (muted) return;
      setUserSpeaking(true);
      setTimeout(() => setUserSpeaking(false), 1200);

      // === Barge-in: Interrupt AI speaking if user starts talking ===
      if (audioRef.current) {
        audioRef.current.pause();
        audioRef.current.src = "";
      }
      setSpeaking(false);

      utteranceIdRef.current += 1;
      const thisUtterance = utteranceIdRef.current;

      const userSpeech = event.results[event.results.length - 1][0].transcript.toLowerCase().trim();
      console.log("ðŸ—£ï¸ Detected speech:", userSpeech);

      // --- Language Selection Phase (ONLY AT START) ---
      if (!langSelected) {
        let detectedLang = null;
        Object.keys(languageKeywords).forEach((lang) => {
          languageKeywords[lang].forEach(keyword => {
            if (userSpeech.includes(keyword)) {
              detectedLang = lang;
            }
          });
        });
        if (detectedLang) {
          setCurrentLang(detectedLang);
          setLangSelected(true); // LOCK language selection now!
          setRecognitionKey((k) => k + 1); // re-mount for new lang
          setHistory([]); // reset history on new language
          await speakText(languages[detectedLang].greeting, detectedLang);
          return;
        } else {
          await speakText(
            "à¤•à¥ƒà¤ªà¤¯à¤¾ à¤…à¤ªà¤¨à¥€ à¤ªà¤¸à¤‚à¤¦à¥€à¤¦à¤¾ à¤­à¤¾à¤·à¤¾ à¤•à¤¾ à¤¨à¤¾à¤® à¤¬à¤¤à¤¾à¤à¤‚à¥¤ For example: English, Hindi, Tamil, etc.",
            "hindi"
          );
          return;
        }
      }

      // --- Normal Conversation Phase ---
      setSpeaking(true);
      // Add user utterance to history
      const newHistory = [...history, { role: "user", content: userSpeech }];
      setHistory(newHistory);

      try {
        // SEND TO CONTEXTUAL ENDPOINT
        const res = await fetch("http://localhost:3000/ask-context", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            history: newHistory,
            language: currentLang,
          }),
        });

        if (!res.ok) throw new Error(`Server responded with ${res.status}`);

        const data = await res.json();
        console.log("AI Reply:", data.reply);

        // Speak only if this is the latest user request
        if (utteranceIdRef.current === thisUtterance) {
          setHistory(h => [...h, { role: "assistant", content: data.reply }]);
          await speakText(data.reply, currentLang);
        }
      } catch (err) {
        console.error("Fetch error:", err.message);
        setSpeaking(false);
      }
    };

    recognition.onend = () => {
      if (connected && !muted && !stoppedByApp) recognition.start();
    };

    recognitionRef.current = recognition;
    if (!muted && !speaking) recognition.start();

    return () => {
      stoppedByApp = true;
      recognition.stop();
    };
    // eslint-disable-next-line
  }, [connected, muted, currentLang, langSelected, recognitionKey, speaking, history]);

  // Mute/unmute logic
  const handleMute = () => {
    setMuted((m) => !m);
    if (!muted) recognitionRef.current?.stop();
    else recognitionRef.current?.start();
  };

  // End chat logic
  const handleEnd = () => {
    setConnected(false);
    setMuted(false);
    setLangSelected(false); // Reset language selection for next session
    setCurrentLang("hindi"); // reset to Hindi on end
    setHistory([]); // clear conversation
    recognitionRef.current?.stop();
    if (audioRef.current) {
      audioRef.current.pause();
      audioRef.current.src = "";
    }
  };

  // Greet and TTS logic with language param
  const speakText = async (text, langKey = currentLang) => {
    setSpeaking(true);
    recognitionRef.current?.stop();
    try {
      const res = await fetch("http://localhost:3000/speak", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ text, language: langKey }),
      });
      const blob = await res.blob();
      const audioUrl = URL.createObjectURL(blob);
      const audio = new Audio(audioUrl);
      audioRef.current = audio;
      audio.onended = () => {
        setSpeaking(false);
        if (connected && !muted) recognitionRef.current?.start();
      };
      audio.play();
      // Resume recognition even while TTS is playing (if browser allows)
      if (connected && !muted && recognitionRef.current) {
        try { recognitionRef.current.start(); } catch(e) {}
      }
    } catch {
      setSpeaking(false);
      if (connected && !muted) recognitionRef.current?.start();
    }
  };

  // Connect button: Play language selection prompt
  const handleConnect = async () => {
    setConnected(true);
    setMuted(false);
    setLangSelected(false); // Always reset language selection for new session
    setCurrentLang("hindi"); // default for recognition
    setRecognitionKey((k) => k + 1);
    setHistory([]); // clear conversation
    await speakText(
      "à¤•à¥ƒà¤ªà¤¯à¤¾ à¤…à¤ªà¤¨à¥€ à¤ªà¤¸à¤‚à¤¦à¥€à¤¦à¤¾ à¤­à¤¾à¤·à¤¾ à¤•à¤¾ à¤¨à¤¾à¤® à¤¬à¤¤à¤¾à¤à¤‚à¥¤ For example: English, Hindi, Tamil, etc.",
      "hindi"
    );
  };

  const formatTime = (sec) =>
    `${String(Math.floor(sec / 60)).padStart(2, "0")}:${String(sec % 60).padStart(2, "0")}`;

  return (
    <div className="ai-agent-ui-container premium-bg">
      <div className="ai-status-bar">
        <span>{formatTime(timer)} â€¢ Voice</span>
        <div className="ai-status-icons">
          <span className="ai-status-icon" />
          <span className="ai-status-icon" />
          <span className="ai-status-battery" />
        </div>
      </div>
      <div className="ai-avatar-ui-premium">
        <span>AI</span>
      </div>
      <div className="ai-agent-title-premium">Navya Legal Agent</div>
      <div className="ai-agent-subtitle-premium">{connected ? "Connected" : "Tap to connect"}</div>
      {connected && (
        <div className={`ai-agent-waves${(speaking || userSpeaking) && !muted ? " speaking" : ""}`}>
          {[...Array(10)].map((_, i) => (
            <div className="ai-wave-bar" key={i} />
          ))}
        </div>
      )}
      {!connected ? (
        <button className="ai-premium-call-btn" onClick={handleConnect}>
          <span className="ai-call-icon" />
        </button>
      ) : (
        <div className="ai-agent-btn-row-premium">
          <button className={`ai-mute-btn${muted ? " muted" : ""}`} onClick={handleMute}>
            <span className={`ai-mic-icon${muted ? " off" : ""}`} />
            <div>Mute</div>
          </button>
          <button className="ai-end-btn" onClick={handleEnd}>
            <span className="ai-end-icon" />
            <div>End</div>
          </button>
        </div>
      )}
    </div>
  );
}