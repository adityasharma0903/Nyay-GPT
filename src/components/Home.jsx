"use client"

import { useState, useEffect, useRef } from "react"
import { getTranscription, textToSpeech } from "../utils/voice"
import MicButton from "./MicButton"
import LanguageToggle from "./LanguageToggle"

const Home = ({ language, setLanguage }) => {
  const [isConversationActive, setIsConversationActive] = useState(false)
  const [isListening, setIsListening] = useState(false)
  const [isSpeaking, setIsSpeaking] = useState(false)
  const [conversationStage, setConversationStage] = useState("idle") // idle, greeting, language-selection, chatting
  const [selectedLanguage, setSelectedLanguage] = useState("")
  const [messages, setMessages] = useState([])
  const [currentTranscript, setCurrentTranscript] = useState("")
  const [isProcessingAPI, setIsProcessingAPI] = useState(false)

  const messagesEndRef = useRef(null)

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" })
  }

  useEffect(() => {
    scrollToBottom()
  }, [messages])

  const addMessage = (text, sender) => {
    setMessages((prev) => [
      ...prev,
      {
        id: Date.now(),
        text,
        sender,
        timestamp: new Date().toLocaleTimeString(),
      },
    ])
  }

  const speakText = async (text, lang = selectedLanguage || language) => {
    setIsSpeaking(true)
    try {
      await textToSpeech(text, lang)
      await new Promise((resolve) => {
        const checkSpeaking = () => {
          if (!window.speechSynthesis.speaking) {
            resolve()
          } else {
            setTimeout(checkSpeaking, 100)
          }
        }
        checkSpeaking()
      })
    } catch (error) {
      console.error("Speech error:", error)
    } finally {
      setIsSpeaking(false)
    }
  }

  const getLegalAdvice = async (question, lang) => {
    setIsProcessingAPI(true)
    console.log("üî• Calling Groq API with:", { question, language: lang })

    try {
      const response = await fetch("http://localhost:8000/legal_advice", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          Accept: "application/json",
        },
        body: JSON.stringify({
          question: question,
          language: lang,
        }),
      })

      console.log("‚úÖ API Response status:", response.status)

      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`)
      }

      const data = await response.json()
      console.log("‚úÖ API Response data:", data)

      if (data.advice) {
        return data.advice
      } else {
        throw new Error("No advice received from API")
      }
    } catch (error) {
      console.error("‚ùå API Error:", error)
      return lang === "hi" ? `‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç, API ‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•à: ${error.message}` : `Sorry, API error: ${error.message}`
    } finally {
      setIsProcessingAPI(false)
    }
  }

  const startConversation = async () => {
    setIsConversationActive(true)
    setConversationStage("greeting")
    setMessages([])

    const greeting = "‡§®‡§Æ‡§∏‡•ç‡§ï‡§æ‡§∞! ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡§æ ‡§ï‡§æ‡§®‡•Ç‡§®‡•Ä ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§π‡•Ç‡§Ç‡•§ ‡§Ü‡§™ ‡§ï‡§ø‡§∏ ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•á‡§Ç ‡§¨‡§æ‡§§ ‡§ï‡§∞‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç - ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Ø‡§æ ‡§Ö‡§Ç‡§ó‡•ç‡§∞‡•á‡§ú‡•Ä?"
    addMessage(greeting, "ai")
    await speakText(greeting, "hi")

    setConversationStage("language-selection")
    setTimeout(() => startListening(), 1000)
  }

  const startListening = async () => {
    if (isListening || isSpeaking) return

    setIsListening(true)
    try {
      const recognitionLang = conversationStage === "language-selection" ? "en" : selectedLanguage || language
      const transcript = await getTranscription(recognitionLang)

      if (transcript.trim()) {
        setCurrentTranscript(transcript)
        addMessage(transcript, "user")
        await handleUserInput(transcript)
      }
    } catch (error) {
      console.error("Listening error:", error)
    } finally {
      setIsListening(false)
    }
  }

  const handleUserInput = async (input) => {
    console.log("üéØ Handling input:", input, "Stage:", conversationStage)

    if (conversationStage === "language-selection") {
      const lowerInput = input.toLowerCase()

      // Check for English
      if (lowerInput.includes("english") || lowerInput.includes("‡§Ö‡§Ç‡§ó‡•ç‡§∞‡•á‡§ú‡•Ä") || lowerInput.includes("‡§á‡§Ç‡§ó‡•ç‡§≤‡§ø‡§∂")) {
        setSelectedLanguage("en")
        if (setLanguage) setLanguage("en")
        setConversationStage("chatting")

        const responseText = "Perfect! I'll help you in English. Please tell me about your legal problem."
        addMessage(responseText, "ai")
        await speakText(responseText, "en")
        setTimeout(() => startListening(), 1000)
        return
      }

      // Check for Hindi
      if (lowerInput.includes("hindi") || lowerInput.includes("‡§π‡§ø‡§Ç‡§¶‡•Ä") || lowerInput.includes("‡§π‡§ø‡§®‡•ç‡§¶‡•Ä")) {
        setSelectedLanguage("hi")
        if (setLanguage) setLanguage("hi")
        setConversationStage("chatting")

        const responseText = "‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ! ‡§Æ‡•à‡§Ç ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§ï‡§∞‡•Ç‡§Ç‡§ó‡§æ‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§Ö‡§™‡§®‡•Ä ‡§ï‡§æ‡§®‡•Ç‡§®‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§¨‡§§‡§æ‡§è‡§Ç‡•§"
        addMessage(responseText, "ai")
        await speakText(responseText, "hi")
        setTimeout(() => startListening(), 1000)
        return
      }

      // If it's a long sentence, treat it as a legal question and auto-detect language
      if (input.length > 10) {
        const detectedLang = /[\u0900-\u097F]/.test(input) ? "hi" : "en"
        setSelectedLanguage(detectedLang)
        if (setLanguage) setLanguage(detectedLang)
        setConversationStage("chatting")

        const acknowledgment =
          detectedLang === "en"
            ? "I understand you're asking in English. Let me help you with your legal concern."
            : "‡§Æ‡•à‡§Ç ‡§∏‡§Æ‡§ù ‡§ó‡§Ø‡§æ ‡§ï‡§ø ‡§Ü‡§™ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§™‡•Ç‡§õ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§ ‡§Ü‡§á‡§è ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡§æ‡§®‡•Ç‡§®‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§ï‡§æ ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§® ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç‡•§"

        addMessage(acknowledgment, "ai")
        await speakText(acknowledgment, detectedLang)

        // Now process the legal question
        console.log("üöÄ Processing legal question:", input)
        const advice = await getLegalAdvice(input, detectedLang)
        addMessage(advice, "ai")
        await speakText(advice, detectedLang)
        setTimeout(() => startListening(), 1000)
        return
      }

      // If nothing detected, ask again
      const responseText = "‡§ï‡•É‡§™‡§Ø‡§æ ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§∞‡•Ç‡§™ ‡§∏‡•á '‡§π‡§ø‡§Ç‡§¶‡•Ä' ‡§Ø‡§æ 'English' ‡§ï‡§π‡•á‡§Ç‡•§"
      addMessage(responseText, "ai")
      await speakText(responseText, "hi")
      setTimeout(() => startListening(), 1500)
    } else if (conversationStage === "chatting") {
      // This is the main legal question handling
      console.log("üöÄ Processing legal question in chatting stage:", input)
      console.log("üåê Selected language:", selectedLanguage)

      // Show processing message
      addMessage("‡§Ü‡§™‡§ï‡•á ‡§∏‡§µ‡§æ‡§≤ ‡§ï‡§æ ‡§ú‡§µ‡§æ‡§¨ ‡§¢‡•Ç‡§Ç‡§¢ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç...", "ai")

      // Get legal advice from API
      const advice = await getLegalAdvice(input, selectedLanguage)

      // Remove processing message and add actual advice
      setMessages((prev) => prev.slice(0, -1))
      addMessage(advice, "ai")
      await speakText(advice, selectedLanguage)

      // Continue listening for more questions
      setTimeout(() => startListening(), 1000)
    }
  }

  const endConversation = () => {
    setIsConversationActive(false)
    setIsListening(false)
    setIsSpeaking(false)
    setConversationStage("idle")
    setSelectedLanguage("")
    setCurrentTranscript("")
    setIsProcessingAPI(false)
    window.speechSynthesis.cancel()

    const endMessage = selectedLanguage === "hi" ? "‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶! ‡§Ü‡§™‡§ï‡§æ ‡§¶‡§ø‡§® ‡§∂‡•Å‡§≠ ‡§π‡•ã‡•§" : "Thank you! Have a great day."
    addMessage(endMessage, "ai")
  }

  const handleMicClick = () => {
    if (!isConversationActive) {
      startConversation()
    } else if (isListening) {
      setIsListening(false)
    } else {
      startListening()
    }
  }

  // Quick language selection
  const selectLanguageDirectly = async (lang) => {
    if (conversationStage === "language-selection") {
      setSelectedLanguage(lang)
      if (setLanguage) setLanguage(lang)
      setConversationStage("chatting")

      const responseText =
        lang === "en"
          ? "Great! I'll help you in English. Please tell me about your legal problem."
          : "‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ! ‡§Æ‡•à‡§Ç ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§ï‡§∞‡•Ç‡§Ç‡§ó‡§æ‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§Ö‡§™‡§®‡•Ä ‡§ï‡§æ‡§®‡•Ç‡§®‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§¨‡§§‡§æ‡§è‡§Ç‡•§"

      addMessage(responseText, "ai")
      await speakText(responseText, lang)
      setTimeout(() => startListening(), 1000)
    }
  }

  return (
    <div className="home-container">
      {/* Language Toggle */}
      <div className="language-section">
        <LanguageToggle language={language} setLanguage={setLanguage} />
      </div>

      {/* Main Content */}
      <div className="main-content">
        <div className="hero-section">
          <h1 className="hero-title">{language === "hi" ? "‡§Ö‡§™‡§®‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§¨‡•ã‡§≤‡•á‡§Ç" : "Speak Your Problem"}</h1>

          {selectedLanguage && (
            <div className="selected-lang-indicator">
              {selectedLanguage === "hi" ? "‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§¨‡§æ‡§§ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç" : "Speaking in English"}
            </div>
          )}

          {conversationStage === "language-selection" && (
            <div className="language-help">
              <p>üó£Ô∏è Say "English" or "‡§π‡§ø‡§Ç‡§¶‡•Ä" clearly</p>
              <p>Or just ask your legal question directly!</p>

              <div className="quick-lang-buttons">
                <button className="quick-lang-btn" onClick={() => selectLanguageDirectly("en")}>
                  English
                </button>
                <button className="quick-lang-btn" onClick={() => selectLanguageDirectly("hi")}>
                  ‡§π‡§ø‡§Ç‡§¶‡•Ä
                </button>
              </div>
            </div>
          )}

          {conversationStage === "chatting" && (
            <div className="chat-help">
              <p>üí¨ ‡§Ö‡§¨ ‡§Ü‡§™ ‡§Ö‡§™‡§®‡•Ä ‡§ï‡§æ‡§®‡•Ç‡§®‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§™‡•Ç‡§õ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç</p>
              <p>üí¨ Now you can ask your legal questions</p>
            </div>
          )}

          {isProcessingAPI && (
            <div className="api-status">
              <p>üîÑ Groq AI ‡§∏‡•á ‡§ú‡§µ‡§æ‡§¨ ‡§≤‡§æ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç...</p>
            </div>
          )}
        </div>

        {/* Voice Conversation Area */}
        {isConversationActive && (
          <div className="conversation-area">
            <div className="messages-container">
              {messages.map((message) => (
                <div key={message.id} className={`message ${message.sender}-message`}>
                  <div className="message-bubble">
                    <p>{message.text}</p>
                    <span className="message-time">{message.timestamp}</span>
                  </div>
                </div>
              ))}
              <div ref={messagesEndRef} />
            </div>
          </div>
        )}

        {/* Mic Button */}
        <div className="mic-section">
          <MicButton
            onClick={handleMicClick}
            listening={isListening}
            speaking={isSpeaking}
            active={isConversationActive}
          />

          {currentTranscript && (
            <div className="transcript-display">
              <p>"{currentTranscript}"</p>
            </div>
          )}

          {isConversationActive && (
            <button className="end-conversation-btn" onClick={endConversation}>
              {language === "hi" ? "‡§¨‡§æ‡§§‡§ö‡•Ä‡§§ ‡§∏‡§Æ‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡•á‡§Ç" : "End Conversation"}
            </button>
          )}
        </div>

        {/* Status Display */}
        <div className="status-section">
          {isSpeaking && (
            <div className="status-indicator speaking">
              {language === "hi" ? "AI ‡§¨‡•ã‡§≤ ‡§∞‡§π‡§æ ‡§π‡•à..." : "AI is speaking..."}
            </div>
          )}
          {isListening && (
            <div className="status-indicator listening">
              {conversationStage === "language-selection" ? "‡§≠‡§æ‡§∑‡§æ ‡§∏‡•Å‡§® ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç..." : "‡§Ü‡§™‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§∏‡•Å‡§® ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç..."}
            </div>
          )}
          {isProcessingAPI && <div className="status-indicator processing">ü§ñ Groq AI Processing...</div>}
          {!isConversationActive && (
            <div className="status-indicator ready">
              {language === "hi" ? "‡§Æ‡§æ‡§á‡§ï ‡§¶‡§¨‡§æ‡§è‡§Ç ‡§î‡§∞ ‡§¨‡§æ‡§§ ‡§ï‡§∞‡§®‡§æ ‡§∂‡•Å‡§∞‡•Ç ‡§ï‡§∞‡•á‡§Ç" : "Press mic to start conversation"}
            </div>
          )}
        </div>

        {/* Debug Info */}
        {conversationStage !== "idle" && (
          <div className="debug-info">
            <p>
              Stage: {conversationStage} | Language: {selectedLanguage || "Not selected"}
            </p>
          </div>
        )}

        {/* Other Features */}
        {!isConversationActive && (
          <div className="other-features">
            {/* <button className="feature-btn">
              {language === "hi" ? "WhatsApp Forward ‡§ö‡•á‡§ï ‡§ï‡§∞‡•á‡§Ç" : "Check WhatsApp Forward"}
            </button>
            <button className="feature-btn">{language === "hi" ? "RTI/FIR ‡§´‡•â‡§∞‡•ç‡§Æ ‡§≠‡§∞‡•á‡§Ç" : "Auto-fill RTI/FIR Form"}</button> */}
          </div>
        )}
      </div>
    </div>
  )
}

export default Home
