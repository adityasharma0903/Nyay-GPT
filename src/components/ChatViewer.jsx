"use client"

import { useEffect, useState, useRef } from "react"
import { useParams, useNavigate } from "react-router-dom"
import { ArrowLeft, Mic, MicOff, Volume2 } from "lucide-react"

const backendBaseUrl =
  window.location.hostname === "localhost" ? "http://localhost:3000" : "https://nyay-gpt.onrender.com"

// Same language configurations as MainLanding
const languages = {
  english: { code: "en-IN" },
  hindi: { code: "hi-IN" },
  punjabi: { code: "pa-IN" },
  tamil: { code: "ta-IN" },
  marathi: { code: "mr-IN" },
  telugu: { code: "te-IN" },
  bengali: { code: "bn-IN" },
  kannada: { code: "kn-IN" },
  malayalam: { code: "ml-IN" },
  gujarati: { code: "gu-IN" },
  urdu: { code: "ur-IN" },
  odia: { code: "or-IN" },
}

const languageKeywords = {
  english: ["english", "‡§á‡§Ç‡§ó‡•ç‡§≤‡§ø‡§∂", "‡§Ö‡§Ç‡§ó‡•ç‡§∞‡•á‡§ú‡•Ä"],
  hindi: ["hindi", "‡§π‡§ø‡§Ç‡§¶‡•Ä", "‡§π‡§ø‡§®‡•ç‡§¶‡•Ä"],
  punjabi: ["punjabi", "‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä", "‡§™‡§Ç‡§ú‡§æ‡§¨‡•Ä"],
  tamil: ["tamil", "‡§§‡§Æ‡§ø‡§≤", "‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç"],
  marathi: ["marathi", "‡§Æ‡§∞‡§æ‡§†‡•Ä"],
  telugu: ["telugu", "‡§§‡•á‡§≤‡•Å‡§ó‡•Ç", "‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å"],
  bengali: ["bengali", "‡¶¨‡ßá‡¶ô‡ßç‡¶ó‡¶≤‡¶ø", "‡¶¨‡¶æ‡¶ô‡¶æ‡¶≤‡¶ø", "‡§¨‡§Ç‡§ó‡§æ‡§≤‡•Ä"],
  kannada: ["kannada", "‡≤ï‡≤®‡≥ç‡≤®‡≤°", "‡§ï‡§®‡•ç‡§®‡§°‡§º"],
  malayalam: ["malayalam", "‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç", "‡§Æ‡§≤‡§Ø‡§æ‡§≤‡§Æ"],
  gujarati: ["gujarati", "‡™ó‡´Å‡™ú‡™∞‡™æ‡™§‡´Ä", "‡§ó‡•Å‡§ú‡§∞‡§æ‡§§‡•Ä"],
  urdu: ["urdu", "ÿßÿ±ÿØŸà", "‡§â‡§∞‡•ç‡§¶‡•Ç"],
  odia: ["odia", "odiya", "‡¨ì‡¨°‡¨º‡¨ø‡¨Ü", "‡§ì‡¨°‡§º‡§ø‡§Ø‡§æ"],
}

export default function ChatViewer() {
  const { chatId } = useParams()
  const navigate = useNavigate()
  const [messages, setMessages] = useState([])
  const [loading, setLoading] = useState(true)
  const scrollRef = useRef(null)

  // Voice functionality states
  const [connected, setConnected] = useState(false)
  const [muted, setMuted] = useState(false)
  const [speaking, setSpeaking] = useState(false)
  const [userSpeaking, setUserSpeaking] = useState(false)
  const [readyToSpeak, setReadyToSpeak] = useState(false)
  const [currentLang, setCurrentLang] = useState("hindi")
  const [recognitionKey, setRecognitionKey] = useState(0)
  const [user, setUser] = useState(null)

  // Voice refs
  const recognitionRef = useRef(null)
  const audioRef = useRef(null)
  const apiCallInProgressRef = useRef(false)
  const utteranceIdRef = useRef(0)

  // Get user from localStorage
  useEffect(() => {
    const storedUser = localStorage.getItem("user")
    if (storedUser) {
      setUser(JSON.parse(storedUser))
    }
  }, [])

  // Function to filter out AI intro/system messages - MORE AGGRESSIVE
  const filterRelevantMessages = (messages) => {
    console.log("üîç Original messages:", messages.length)

    // More comprehensive intro keywords
    const introKeywords = [
      "‡§®‡§Æ‡§∏‡•ç‡§§‡•á",
      "hello",
      "‡§Æ‡•à‡§Ç ‡§®‡•ç‡§Ø‡§æ‡§Ø",
      "i'm nyay",
      "i am nyay",
      "legal assistant",
      "‡§ï‡§æ‡§®‡•Ç‡§®‡•Ä ‡§∏‡§π‡§æ‡§Ø‡§ï",
      "chanakya ai",
      "‡§ö‡§æ‡§£‡§ï‡•ç‡§Ø",
      "‡§Ü‡§™‡§ï‡•Ä ‡§¨‡•á‡§π‡§§‡§∞ ‡§Æ‡§¶‡§¶",
      "for better assistance",
      "preferred language",
      "‡§™‡§∏‡§Ç‡§¶‡•Ä‡§¶‡§æ ‡§≠‡§æ‡§∑‡§æ",
      "‡§Æ‡•à‡§Ç ‡§è‡§ï ‡§≠‡§æ‡§∞‡§§ ‡§ï‡§æ",
      "‡§ï‡§æ‡§®‡•Ç‡§®‡•Ä ‡§®‡•ç‡§Ø‡§æ‡§Ø",
      "‡§®‡•ç‡§Ø‡§æ‡§Ø ‡§ú‡•Ä‡§™‡•Ä‡§ü‡•Ä",
      "‡§Ü‡§™‡§ï‡§æ ‡§™‡§π‡§≤‡§æ ‡§∏‡§µ‡§æ‡§≤",
      "your first question",
      "‡§Æ‡•Å‡§ù‡•á ‡§ú‡§µ‡§æ‡§¨ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç",
      "‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡•ã‡§Ç ‡§ï‡•Ä ‡§∏‡•ç‡§µ‡•Ä‡§ï‡§æ‡§∞",
      "‡§Ü‡§™‡§ï‡•á ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡•ç‡§µ‡•Ä‡§ï‡§æ‡§∞ ‡§ï‡§∞ ‡§≤‡§ø‡§Ø‡§æ",
      "‡§Ü‡§™ ‡§Ö‡§™‡§®‡§æ ‡§Ö‡§ó‡§≤‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç",
    ]

    const filtered = messages.filter((msg, index) => {
      const content = msg.content.toLowerCase()

      // Skip first 2 messages if they look like system messages
      if (index < 2) {
        const isSystemMessage =
          introKeywords.some((keyword) => content.includes(keyword.toLowerCase())) || content.length < 100 // Very short messages are likely intros

        if (isSystemMessage) {
          console.log(`üö´ Skipping message ${index + 1} (system/intro):`, msg.content.substring(0, 50))
          return false
        }
      }

      // For assistant messages, be more strict
      if (msg.role === "assistant") {
        const isIntroMessage = introKeywords.some((keyword) => content.includes(keyword.toLowerCase()))

        // Skip if it contains intro keywords OR is very generic
        if (isIntroMessage || content.includes("‡§ï‡•É‡§™‡§Ø‡§æ ‡§Ö‡§™‡§®‡§æ") || content.includes("please ask")) {
          console.log(`üö´ Filtering assistant intro:`, msg.content.substring(0, 50))
          return false
        }
      }

      // Always keep user messages (they are genuine questions)
      if (msg.role === "user") {
        console.log(`‚úÖ Keeping user message:`, msg.content.substring(0, 50))
        return true
      }

      // Keep assistant messages that seem like real responses
      console.log(`‚úÖ Keeping assistant response:`, msg.content.substring(0, 50))
      return true
    })

    console.log("üîç Filtered messages:", filtered.length)
    console.log("üîç Final filtered messages:")
    filtered.forEach((msg, i) => {
      console.log(`${i + 1}. ${msg.role}: ${msg.content.substring(0, 80)}...`)
    })

    return filtered
  }

  // Fetch chat messages
  useEffect(() => {
    const fetchChat = async () => {
      try {
        const user = JSON.parse(localStorage.getItem("user"))
        const token = user?.token

        const res = await fetch(`https://nyay-gpt.onrender.com/history/${chatId}`, {
          headers: {
            Authorization: `Bearer ${token}`,
          },
        })

        if (!res.ok) throw new Error("Failed to fetch chat")
        const data = await res.json()
        const chatMessages = data.chat?.messages || []

        // Filter out intro messages for better context
        const filteredMessages = filterRelevantMessages(chatMessages)
        setMessages(chatMessages) // Keep all messages for UI

        console.log("üìö Total messages loaded:", chatMessages.length)
        console.log("üìö Relevant messages for AI:", filteredMessages.length)

        // Auto-detect language from chat history
        detectLanguageFromHistory(filteredMessages)
      } catch (error) {
        console.error("Chat load error:", error.message)
        setMessages([])
      } finally {
        setLoading(false)
        setTimeout(() => {
          scrollRef.current?.scrollIntoView({ behavior: "smooth" })
        }, 100)
      }
    }

    fetchChat()
  }, [chatId])

  // Auto-detect language from chat history
  const detectLanguageFromHistory = (chatMessages) => {
    if (chatMessages.length === 0) return

    // Check last few messages for language patterns
    const recentMessages = chatMessages.slice(-5)
    const combinedText = recentMessages
      .map((msg) => msg.content)
      .join(" ")
      .toLowerCase()

    // Simple language detection based on keywords
    for (const [lang, keywords] of Object.entries(languageKeywords)) {
      if (keywords.some((keyword) => combinedText.includes(keyword.toLowerCase()))) {
        setCurrentLang(lang)
        console.log("üåê Detected language:", lang)
        return
      }
    }

    // Check for Hindi/Devanagari script
    if (/[\u0900-\u097F]/.test(combinedText)) {
      setCurrentLang("hindi")
      console.log("üåê Detected Hindi script")
    } else if (/[a-zA-Z]/.test(combinedText)) {
      setCurrentLang("english")
      console.log("üåê Detected English")
    }
  }

  // Audio unlock for mobile devices
  useEffect(() => {
    const unlockAudio = () => {
      try {
        const buffer = new AudioContext().createBuffer(1, 1, 22050)
        const source = new AudioContext().createBufferSource()
        source.buffer = buffer
        source.connect(new AudioContext().destination)
        source.start(0)
      } catch (e) {
        console.log("Audio unlock failed:", e)
      }
      document.removeEventListener("touchend", unlockAudio, true)
      document.removeEventListener("click", unlockAudio, true)
    }
    document.addEventListener("touchend", unlockAudio, true)
    document.addEventListener("click", unlockAudio, true)
    return () => {
      document.removeEventListener("touchend", unlockAudio, true)
      document.removeEventListener("click", unlockAudio, true)
    }
  }, [])

  // Speech recognition setup
  useEffect(() => {
    if (!connected) return
    if (muted || speaking) return

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
    if (!SpeechRecognition) {
      alert("Speech recognition not supported in this browser. Use the latest Chrome.")
      return
    }

    const langToUse = currentLang && languages[currentLang] ? languages[currentLang].code : "hi-IN"
    const recognition = new SpeechRecognition()
    recognition.lang = langToUse
    recognition.continuous = true
    recognition.interimResults = false

    let stoppedByApp = false

    recognition.onresult = async (event) => {
      if (muted || speaking || apiCallInProgressRef.current) return

      setUserSpeaking(true)
      setReadyToSpeak(false)
      setTimeout(() => setUserSpeaking(false), 1200)
      recognition.stop()

      utteranceIdRef.current += 1
      const thisUtterance = utteranceIdRef.current
      const userSpeech = event.results[event.results.length - 1][0].transcript.trim()

      console.log("üé§ User said:", userSpeech)

      if (!apiCallInProgressRef.current) {
        apiCallInProgressRef.current = true
        setSpeaking(true)

        // ‚úÖ AGGRESSIVE filtering to exclude ALL intro messages
        console.log("üìä BEFORE filtering - Total messages:", messages.length)
        const relevantHistory = filterRelevantMessages(messages)
        console.log("üìä AFTER filtering - Relevant messages:", relevantHistory.length)

        const newUserMessage = { role: "user", content: userSpeech }
        const fullChatHistory = [...relevantHistory, newUserMessage]

        console.log("üì§ FINAL PAYLOAD TO AI:")
        console.log("üì§ Total messages being sent:", fullChatHistory.length)
        fullChatHistory.forEach((msg, i) => {
          console.log(`üì§ ${i + 1}. [${msg.role.toUpperCase()}]: ${msg.content}`)
        })

        // Update UI with all messages (including new user message)
        setMessages((prev) => [...prev, newUserMessage])

        // Save user message to backend
        await saveUserChat(newUserMessage, chatId)

        try {
          // ‚úÖ Call assistant API with HEAVILY FILTERED chat history
          const res = await fetch(`${backendBaseUrl}/ask-context`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
              history: fullChatHistory, // ‚úÖ This now excludes ALL intro messages
              language: currentLang,
            }),
          })

          if (!res.ok) throw new Error(`Server responded with ${res.status}`)
          const data = await res.json()

          console.log("üì• AI Response received:", data.reply.substring(0, 100))

          // If this is still the latest utterance, process reply
          if (utteranceIdRef.current === thisUtterance && apiCallInProgressRef.current) {
            const assistantMessage = { role: "assistant", content: data.reply }

            // Add assistant reply to UI
            setMessages((prev) => [...prev, assistantMessage])

            // Save assistant reply to backend
            await saveUserChat(assistantMessage, chatId)

            // Speak reply and prepare for next
            await speakText(data.reply, currentLang)
            setRecognitionKey((k) => k + 1)
          }
        } catch (err) {
          console.error("API Error:", err)
          setSpeaking(false)
          setRecognitionKey((k) => k + 1)
        } finally {
          apiCallInProgressRef.current = false
        }
      }
    }

    recognition.onend = () => {
      if (connected && !muted && !stoppedByApp && !speaking) {
        try {
          recognition.start()
        } catch (e) {
          console.log("Recognition restart failed:", e)
        }
      }
    }

    recognitionRef.current = recognition
    try {
      recognition.start()
      console.log("üé§ Speech recognition started")
    } catch (e) {
      console.log("Recognition start failed:", e)
    }

    return () => {
      stoppedByApp = true
      recognition.stop()
    }
  }, [connected, muted, recognitionKey, speaking, currentLang, messages, chatId])

  // Save chat function
  const saveUserChat = async (messageObj, existingChatId) => {
    if (!user?.token) {
      console.log("No user token available")
      return
    }

    try {
      const res = await fetch(`${backendBaseUrl}/history`, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${user.token}`,
        },
        body: JSON.stringify({
          chatId: existingChatId,
          message: messageObj,
        }),
      })

      const data = await res.json()
      console.log("üíæ Saved message to backend:", messageObj.role)
      return data.chatId
    } catch (err) {
      console.error("Failed to save chat:", err)
    }
  }

  // Text to speech function
  const speakText = async (text, langKey = currentLang || "hindi") => {
    console.log("üé§ Starting speech:", text.substring(0, 50) + "...")

    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop()
      } catch (e) {}
    }
    if (audioRef.current) {
      audioRef.current.pause()
      audioRef.current.src = ""
    }

    try {
      const res = await fetch(`${backendBaseUrl}/speak`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ text, language: langKey }),
      })

      if (!res.ok) {
        throw new Error(`TTS request failed: ${res.status}`)
      }

      const blob = await res.blob()
      const audioUrl = URL.createObjectURL(blob)
      const audio = new window.Audio(audioUrl)
      audioRef.current = audio

      audio.onended = () => {
        setSpeaking(false)
        setReadyToSpeak(true)
        console.log("üîä Speech ended, ready for next input")
      }
      audio.onerror = (e) => {
        console.error("Audio playback error:", e)
        setSpeaking(false)
        setReadyToSpeak(true)
      }

      setSpeaking(true)
      setReadyToSpeak(false)
      try {
        await audio.play()
      } catch (err) {
        console.error("Audio play failed:", err)
        alert("Please tap anywhere on the screen to enable audio, then try again.")
        setSpeaking(false)
        setReadyToSpeak(false)
      }
    } catch (error) {
      console.error("TTS error:", error)
      setSpeaking(false)
      setReadyToSpeak(false)
    }
  }

  // Handle microphone toggle
  const handleMicToggle = () => {
    if (!connected) {
      // Start voice conversation
      setConnected(true)
      setMuted(false)
      setRecognitionKey((k) => k + 1)

      const relevantMessages = filterRelevantMessages(messages)
      console.log("üé§ Voice chat started with", relevantMessages.length, "relevant messages")

      // Welcome message for continuing conversation
      const welcomeMessage =
        currentLang === "hindi"
          ? "‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•á ‡§™‡§ø‡§õ‡§≤‡•á ‡§∏‡§µ‡§æ‡§≤‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡§Æ‡§ù ‡§ó‡§Ø‡§æ ‡§π‡•Ç‡§Ç‡•§ ‡§Ü‡§™ ‡§Ö‡§™‡§®‡§æ ‡§Ö‡§ó‡§≤‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§"
          : "I understand your previous questions. You can ask your next question."

      speakText(welcomeMessage, currentLang)
    } else {
      // End voice conversation
      setConnected(false)
      setMuted(false)
      setSpeaking(false)
      setReadyToSpeak(false)
      recognitionRef.current?.stop()
      if (audioRef.current) {
        audioRef.current.pause()
        audioRef.current.src = ""
      }
      apiCallInProgressRef.current = false
      console.log("üé§ Voice chat ended")
    }
  }

  // Handle mute toggle
  const handleMute = () => {
    setMuted((m) => !m)
    if (!muted) {
      recognitionRef.current?.stop()
      if (audioRef.current) {
        audioRef.current.pause()
        audioRef.current.src = ""
      }
      setSpeaking(false)
      setReadyToSpeak(false)
    } else {
      setRecognitionKey((k) => k + 1)
    }
  }

  const containerStyle = {
    minHeight: "100vh",
    background: "linear-gradient(135deg, #0c0c0c 0%, #1a1a2e 50%, #16213e 100%)",
    color: "#ffffff",
    display: "flex",
    flexDirection: "column",
    fontFamily: "system-ui, -apple-system, sans-serif",
  }

  const headerStyle = {
    display: "flex",
    alignItems: "center",
    justifyContent: "space-between",
    padding: "1rem",
    borderBottom: "1px solid rgba(255, 255, 255, 0.1)",
    background: "rgba(17, 24, 39, 0.8)",
    backdropFilter: "blur(10px)",
    position: "sticky",
    top: 0,
    zIndex: 10,
  }

  const buttonStyle = {
    padding: "0.5rem",
    borderRadius: "50%",
    border: "none",
    cursor: "pointer",
    transition: "all 0.3s ease",
    display: "flex",
    alignItems: "center",
    justifyContent: "center",
  }

  const backButtonStyle = {
    ...buttonStyle,
    background: "#374151",
    color: "white",
    marginRight: "1rem",
  }

  const micButtonStyle = {
    ...buttonStyle,
    padding: "0.75rem",
    background: connected ? (readyToSpeak ? "#DC2626" : "#059669") : "#2563EB",
    color: "white",
    boxShadow: readyToSpeak ? "0 0 20px rgba(220, 38, 38, 0.5)" : "none",
  }

  const muteButtonStyle = {
    ...buttonStyle,
    background: muted ? "#DC2626" : "#374151",
    color: "white",
  }

  const messagesContainerStyle = {
    flex: 1,
    overflowY: "auto",
    padding: "1.5rem 1rem",
    display: "flex",
    flexDirection: "column",
    gap: "1rem",
  }

  const messageStyle = (isUser) => ({
    maxWidth: "80%",
    padding: "0.75rem 1.25rem",
    fontSize: "0.875rem",
    borderRadius: "1rem",
    whiteSpace: "pre-wrap",
    lineHeight: "1.5",
    alignSelf: isUser ? "flex-end" : "flex-start",
    background: isUser ? "#2563EB" : "#1E293B",
    color: "#ffffff",
    borderBottomRightRadius: isUser ? "0.25rem" : "1rem",
    borderBottomLeftRadius: isUser ? "1rem" : "0.25rem",
    boxShadow: "0 2px 4px rgba(0, 0, 0, 0.1)",
  })

  const statusBarStyle = {
    background: "#374151",
    padding: "0.5rem 1rem",
    textAlign: "center",
    fontSize: "0.875rem",
    display: "flex",
    alignItems: "center",
    justifyContent: "center",
    gap: "1rem",
  }

  const instructionsStyle = {
    background: "#374151",
    padding: "0.75rem 1rem",
    textAlign: "center",
    fontSize: "0.875rem",
    color: "#D1D5DB",
  }

  // Calculate relevant message count for display
  const relevantMessageCount = filterRelevantMessages(messages).length


  
  return (
    <div style={containerStyle}>
      {/* Header */}
      <div style={headerStyle}>
        <div style={{ display: "flex", alignItems: "center" }}>
          <button
            onClick={() => navigate("/")}
            style={backButtonStyle}
            onMouseEnter={(e) => (e.target.style.background = "#4B5563")}
            onMouseLeave={(e) => (e.target.style.background = "#374151")}
          >
            <ArrowLeft size={20} />
          </button>
          <h1 style={{ fontSize: "1.125rem", fontWeight: "600", margin: 0 }}>
            Chat Viewer {messages.length > 0 && `(${relevantMessageCount} relevant)`}
          </h1>
        </div>

        {/* Voice Controls */}
        <div style={{ display: "flex", alignItems: "center", gap: "0.75rem" }}>
          {/* Voice Status */}
          <div style={{ fontSize: "0.875rem", color: "#9CA3AF", minWidth: "120px" }}>
            {speaking && (
              <div style={{ display: "flex", alignItems: "center", gap: "0.5rem" }}>
                <Volume2 size={16} style={{ color: "#60A5FA" }} />
                <span>AI Speaking...</span>
              </div>
            )}
            {userSpeaking && "üé§ Listening..."}
            {readyToSpeak && !speaking && !userSpeaking && (
              <span style={{ color: "#F87171", fontWeight: "600" }}>üé§ Ready!</span>
            )}
            {connected && !speaking && !userSpeaking && !readyToSpeak && "Voice Active"}
            {!connected && "Voice Inactive"}
          </div>

          {/* Mute Button (only show when connected) */}
          {connected && (
            <button
              onClick={handleMute}
              style={muteButtonStyle}
              onMouseEnter={(e) => {
                e.target.style.background = muted ? "#B91C1C" : "#4B5563"
              }}
              onMouseLeave={(e) => {
                e.target.style.background = muted ? "#DC2626" : "#374151"
              }}
              title={muted ? "Unmute" : "Mute"}
            >
              {muted ? <MicOff size={16} /> : <Mic size={16} />}
            </button>
          )}

          {/* Main Mic Button */}
          <button
            onClick={handleMicToggle}
            style={micButtonStyle}
            onMouseEnter={(e) => {
              if (connected) {
                e.target.style.background = readyToSpeak ? "#B91C1C" : "#047857"
              } else {
                e.target.style.background = "#1D4ED8"
              }
            }}
            onMouseLeave={(e) => {
              if (connected) {
                e.target.style.background = readyToSpeak ? "#DC2626" : "#059669"
              } else {
                e.target.style.background = "#2563EB"
              }
            }}
            title={connected ? "End Voice Chat" : "Start Voice Chat"}
          >
            {connected ? userSpeaking ? <Mic size={20} /> : <MicOff size={20} /> : <Mic size={20} />}
          </button>
        </div>
      </div>

      {/* Voice Status Bar */}
      {connected && (
        <div style={statusBarStyle}>
          <span style={{ color: "#10B981" }}>‚óè Voice Chat Active</span>
          <span style={{ color: "#9CA3AF" }}>
            Language: {currentLang} | Relevant: {relevantMessageCount} messages
          </span>
          {speaking && (
            <div style={{ display: "flex", alignItems: "center", gap: "0.5rem" }}>
              <div
                style={{
                  width: "8px",
                  height: "8px",
                  background: "#60A5FA",
                  borderRadius: "50%",
                  animation: "pulse 2s infinite",
                }}
              />
              <span style={{ color: "#60A5FA" }}>AI is speaking...</span>
            </div>
          )}
          {readyToSpeak && (
            <div style={{ display: "flex", alignItems: "center", gap: "0.5rem" }}>
              <div
                style={{
                  width: "8px",
                  height: "8px",
                  background: "#F87171",
                  borderRadius: "50%",
                  animation: "pulse 2s infinite",
                }}
              />
              <span style={{ color: "#F87171", fontWeight: "600" }}>Speak now!</span>
            </div>
          )}
        </div>
      )}

      {/* Messages */}
      <div style={messagesContainerStyle}>
        {loading ? (
          <p style={{ textAlign: "center", color: "#9CA3AF" }}>Fetching messages...</p>
        ) : messages.length === 0 ? (
          <p style={{ textAlign: "center", color: "#9CA3AF" }}>No messages found in this chat.</p>
        ) : (
          messages.map((msg, index) => (
            <div key={index} style={messageStyle(msg.role === "user")}>
              {msg.content}
            </div>
          ))
        )}
        <div ref={scrollRef} />
      </div>

      {/* Voice Instructions */}
      {connected && (
        <div style={instructionsStyle}>
          {userSpeaking ? (
            <span style={{ color: "#10B981" }}>üé§ Listening to your question...</span>
          ) : speaking ? (
            <span style={{ color: "#60A5FA" }}>üîä AI is responding...</span>
          ) : readyToSpeak ? (
            <span style={{ color: "#F87171", fontWeight: "600" }}>
              üé§ SPEAK NOW - I understand your previous questions
            </span>
          ) : (
            <span>Voice chat is active. I understand your {relevantMessageCount} previous questions.</span>
          )}
        </div>
      )}

      {/* CSS for animations */}
      <style>{`
        @keyframes pulse {
          0%, 100% {
            opacity: 1;
          }
          50% {
            opacity: 0.5;
          }
        }
      `}</style>
    </div>
  )
}
